<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Retention &amp; Recognition</title>
  <style>
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <style>
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
<!-- <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"> -->
<link rel="stylesheet" type="text/css" href="http://projects.illc.uva.nl/LaCo/clclab/assets/styles.css">
<link rel="stylesheet" href="http://projects.illc.uva.nl/LaCo/clclab/assets/iconic/css/open-iconic-bootstrap.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.8.3/katex.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.8.3/contrib/auto-render.min.js"></script><script>document.addEventListener("DOMContentLoaded", function() {
    renderMathInElement(document.body);
  });</script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.8.3/katex.min.css" />
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
<style>
  body {
    counter-reset: question-counter assignment-counter exercise-counter bonus-counter;
  }

  .exercise, 
  .question,
  .assignment,
  .bonus {
    border-width: 1px;
    border-style: solid;
    padding: .5rem 1rem;
    border-radius: 2px;
    margin: 1rem 0em;
  }

  .question {
    background-color: rgba(50, 150, 150, 0.2);
    border-color: rgba(50, 150, 150, 0.6);
  }

  .exercise {
    background-color: rgba(0, 0, 0, 0.05);
    border-color: rgba(0, 0, 0, 0.2);
  }

  .assignment {
    background-color: rgba(200, 50, 50, 0.2);
    border-color: rgba(200, 50, 50, 0.6);
  }

  .bonus {
    background-color: rgba(250, 150, 50, 0.2);
    border-color: rgba(250, 150, 50, 0.6);
  }

  .exercise:before,
  .question:before,
  .assignment:before,
  .bonus:before {
    display: block;
    font-size: 1rem;
    font-weight: bold;
    margin-bottom: 1em;
  }

  .question:before {
    content: "Question " counter(question-counter);
    counter-increment: question-counter;
  }

  .exercise:before {
    content: "Exercise " counter(exercise-counter);
    counter-increment: exercise-counter;
  }

  .assignment:before {
    content: "Assignment " counter(assignment-counter);
    counter-increment: assignment-counter;
  }

  .bonus:before {
    content: "Bonus " counter(bonus-counter);
    counter-increment: bonus-counter;
	}

	#TOC a {
		color: #999;
	}

	#TOC ul {
		list-style: none;
	}

	#TOC > ul {
		padding: 0;
	}

	#TOC > ul > li {
		padding-bottom: 1em;
	}

	#TOC > ul ul{
		padding-left: 1rem;
	}

	#TOC .toc-section-number {
		display:none;
	}

	article h1 {
		margin-top: 5rem;
		margin-bottom: 1rem;
		line-height: 1em;
	}

	article h2 {
		font-size: 1.5rem;
		margin-top: 2.5rem;
	}

	li p {
		margin: 0;
	}

	section.footnotes { 
		color: rgba(0, 75, 68, 0.6);
		font-family: "Ubuntu Mono";
		font-size: 14.4px;
		font-weight: 400;
		line-height: 21.6px;
		margin-bottom: 16px;
		margin-top: 0px;
		text-align: left;
	}

	section.footnotes:before { 
		content: "Notes";
		display:block;

		color: rgb(0, 75, 68);
		font-family: "Ubuntu Mono";
		font-size: 40px;
		font-weight: 500;
		line-height: 40px;
		margin-bottom: 16px;
		margin-top: 80px;
		text-align: left;
	}

</style>
</head>
<body>
  <article class="blog">
    <div class="lab-intro">
		<div class="container">
			<header class="offset-lg-3 pt-5 lead my-5">
        <p>
          <span class="badge badge-pill badge-light">Computer lab</span>
        </p>
				<h1 class="display-1">Retention &amp; Recognition</h1>
        <p class="subtitle">A Computational Model for Segmentation in Artificial Language Learning</p>
				<p class="author mt-5">
                    </p>
			</header>
			<div class="clc-pattern bg-div dark">
				<!--?xml version="1.0" encoding="utf-8"?-->

<svg version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" width="2000px" height="2000px" viewBox="20 10 2000 2000" xml:space="preserve">
	<!-- enable-background="new 0 0 204.891 151.016" -->

	<defs>
		<pattern id="clc-pattern-unit" x="0" y="0" width="204.891" height="151.016" patternUnits="userSpaceOnUse">
			<path class="clc-pattern-unit-letter" d="M3.081,21.337c0-1.359,0.214-2.641,0.641-3.84c0.426-1.2,1.08-2.246,1.96-3.141c0.88-0.893,1.993-1.6,3.341-2.119
				c1.346-0.521,2.953-0.78,4.819-0.78c1.12,0,2.134,0.079,3.04,0.239s1.826,0.428,2.76,0.801l-1.08,3.96
				c-0.533-0.187-1.127-0.354-1.779-0.5c-0.654-0.146-1.487-0.22-2.5-0.22c-1.174,0-2.154,0.14-2.94,0.42
				c-0.787,0.279-1.42,0.666-1.899,1.16c-0.48,0.493-0.828,1.086-1.041,1.779s-0.32,1.439-0.32,2.24
				c0,1.734,0.486,3.094,1.461,4.08c0.973,0.986,2.633,1.48,4.98,1.48c0.772,0,1.579-0.054,2.42-0.16
				c0.84-0.107,1.605-0.28,2.299-0.521l0.721,4.04c-0.693,0.268-1.533,0.486-2.52,0.66c-0.987,0.173-2.147,0.26-3.48,0.26
				c-1.92,0-3.566-0.254-4.939-0.76c-1.375-0.506-2.5-1.2-3.381-2.08c-0.88-0.88-1.527-1.92-1.939-3.12
				C3.288,24.017,3.081,22.724,3.081,21.337z"></path>
			<path class="clc-pattern-unit-letter" d="M40.002,29.937c-0.08,0.055-0.261,0.146-0.54,0.28c-0.28,0.134-0.646,0.274-1.1,0.42
				c-0.454,0.146-1.008,0.273-1.66,0.38c-0.654,0.106-1.395,0.16-2.221,0.16c-2.267,0-3.92-0.673-4.959-2.02
				c-1.041-1.347-1.561-3.313-1.561-5.9V7.297h-5.2v-4.08h10.12v20.399c0,1.281,0.253,2.147,0.76,2.601
				c0.506,0.454,1.146,0.681,1.92,0.681c0.986,0,1.813-0.134,2.48-0.4c0.666-0.267,1.105-0.44,1.32-0.52L40.002,29.937z"></path>
			<path class="clc-pattern-unit-letter" d="M43.081,21.337c0-1.359,0.214-2.641,0.641-3.84c0.426-1.2,1.08-2.246,1.96-3.141c0.88-0.893,1.993-1.6,3.341-2.119
				c1.346-0.521,2.953-0.78,4.819-0.78c1.12,0,2.134,0.079,3.04,0.239s1.826,0.428,2.76,0.801l-1.08,3.96
				c-0.533-0.187-1.127-0.354-1.779-0.5c-0.654-0.146-1.487-0.22-2.5-0.22c-1.174,0-2.154,0.14-2.94,0.42
				c-0.787,0.279-1.42,0.666-1.899,1.16c-0.48,0.493-0.828,1.086-1.041,1.779s-0.32,1.439-0.32,2.24
				c0,1.734,0.486,3.094,1.461,4.08c0.973,0.986,2.633,1.48,4.98,1.48c0.772,0,1.579-0.054,2.42-0.16
				c0.84-0.107,1.605-0.28,2.299-0.521l0.721,4.04c-0.693,0.268-1.533,0.486-2.52,0.66c-0.987,0.173-2.147,0.26-3.48,0.26
				c-1.92,0-3.566-0.254-4.939-0.76c-1.375-0.506-2.5-1.2-3.381-2.08c-0.88-0.88-1.527-1.92-1.939-3.12
				C43.288,24.017,43.081,22.724,43.081,21.337z"></path>
			<path class="clc-pattern-unit-letter" d="M80.002,29.937c-0.08,0.055-0.261,0.146-0.54,0.28c-0.28,0.134-0.646,0.274-1.1,0.42
				c-0.454,0.146-1.008,0.273-1.66,0.38c-0.654,0.106-1.395,0.16-2.221,0.16c-2.267,0-3.92-0.673-4.959-2.02
				c-1.041-1.347-1.561-3.313-1.561-5.9V7.297h-5.2v-4.08h10.12v20.399c0,1.281,0.253,2.147,0.76,2.601
				c0.506,0.454,1.146,0.681,1.92,0.681c0.986,0,1.813-0.134,2.48-0.4c0.666-0.267,1.105-0.44,1.32-0.52L80.002,29.937z"></path>
			<path class="clc-pattern-unit-letter" d="M83.081,21.337c0-1.359,0.214-2.641,0.641-3.84c0.426-1.2,1.08-2.246,1.96-3.141c0.88-0.893,1.993-1.6,3.341-2.119
				c1.346-0.521,2.953-0.78,4.82-0.78c1.119,0,2.133,0.079,3.039,0.239s1.826,0.428,2.76,0.801l-1.08,3.96
				c-0.533-0.187-1.127-0.354-1.779-0.5c-0.654-0.146-1.486-0.22-2.5-0.22c-1.174,0-2.154,0.14-2.939,0.42
				c-0.787,0.279-1.42,0.666-1.9,1.16c-0.48,0.493-0.828,1.086-1.041,1.779s-0.32,1.439-0.32,2.24c0,1.734,0.486,3.094,1.461,4.08
				c0.973,0.986,2.633,1.48,4.98,1.48c0.773,0,1.58-0.054,2.42-0.16c0.84-0.107,1.605-0.28,2.299-0.521l0.721,4.04
				c-0.693,0.268-1.533,0.486-2.52,0.66c-0.986,0.173-2.146,0.26-3.48,0.26c-1.92,0-3.566-0.254-4.939-0.76
				c-1.375-0.506-2.5-1.2-3.381-2.08c-0.88-0.88-1.527-1.92-1.939-3.12C83.288,24.017,83.081,22.724,83.081,21.337z"></path>
			<path class="clc-pattern-unit-letter" d="M201.235,25.217c-0.412,1.2-1.061,2.24-1.939,3.12c-0.881,0.88-2.006,1.574-3.381,2.08
				c-1.373,0.506-3.02,0.76-4.939,0.76c-1.334,0-2.494-0.087-3.48-0.26c-0.986-0.174-1.826-0.393-2.52-0.66l0.721-4.04
				c0.693,0.24,1.459,0.413,2.299,0.521c0.84,0.106,1.646,0.16,2.42,0.16c2.348,0,4.008-0.494,4.98-1.48
				c0.975-0.986,1.461-2.346,1.461-4.08c0-0.801-0.107-1.547-0.32-2.24s-0.561-1.286-1.041-1.779c-0.48-0.494-1.113-0.881-1.9-1.16
				c-0.785-0.28-1.766-0.42-2.939-0.42c-1.014,0-1.846,0.073-2.5,0.22c-0.652,0.146-1.246,0.313-1.779,0.5l-1.08-3.96
				c0.934-0.373,1.854-0.641,2.76-0.801s1.92-0.239,3.039-0.239c1.867,0,3.475,0.26,4.82,0.78c1.348,0.52,2.461,1.227,3.34,2.119
				c0.881,0.895,1.535,1.94,1.961,3.141c0.426,1.199,0.641,2.48,0.641,3.84C201.856,22.724,201.649,24.017,201.235,25.217z"></path>
			<path class="clc-pattern-unit-letter" d="M165.575,25.978c0.215,0.079,0.654,0.253,1.32,0.52s1.494,0.4,2.48,0.4c0.773,0,1.414-0.227,1.92-0.681
				c0.506-0.453,0.76-1.319,0.76-2.601V3.217h10.119v4.08h-5.199v15.96c0,2.587-0.52,4.554-1.561,5.9
				c-1.039,1.347-2.693,2.02-4.959,2.02c-0.826,0-1.566-0.054-2.221-0.16c-0.652-0.106-1.207-0.233-1.66-0.38
				c-0.453-0.146-0.82-0.286-1.1-0.42s-0.461-0.226-0.541-0.28L165.575,25.978z"></path>
			<path class="clc-pattern-unit-letter" d="M161.235,25.217c-0.412,1.2-1.061,2.24-1.939,3.12c-0.881,0.88-2.006,1.574-3.381,2.08
				c-1.373,0.506-3.02,0.76-4.939,0.76c-1.334,0-2.494-0.087-3.48-0.26c-0.986-0.174-1.826-0.393-2.52-0.66l0.721-4.04
				c0.693,0.24,1.459,0.413,2.299,0.521c0.84,0.106,1.646,0.16,2.42,0.16c2.348,0,4.008-0.494,4.98-1.48
				c0.975-0.986,1.461-2.346,1.461-4.08c0-0.801-0.107-1.547-0.32-2.24s-0.561-1.286-1.041-1.779c-0.48-0.494-1.113-0.881-1.9-1.16
				c-0.785-0.28-1.766-0.42-2.939-0.42c-1.014,0-1.846,0.073-2.5,0.22c-0.652,0.146-1.246,0.313-1.779,0.5l-1.08-3.96
				c0.934-0.373,1.854-0.641,2.76-0.801s1.92-0.239,3.039-0.239c1.867,0,3.475,0.26,4.82,0.78c1.348,0.52,2.461,1.227,3.34,2.119
				c0.881,0.895,1.535,1.94,1.961,3.141c0.426,1.199,0.641,2.48,0.641,3.84C161.856,22.724,161.649,24.017,161.235,25.217z"></path>
			<path class="clc-pattern-unit-letter" d="M125.575,25.978c0.215,0.079,0.654,0.253,1.32,0.52s1.494,0.4,2.48,0.4c0.773,0,1.414-0.227,1.92-0.681
				c0.506-0.453,0.76-1.319,0.76-2.601V3.217h10.119v4.08h-5.199v15.96c0,2.587-0.52,4.554-1.561,5.9
				c-1.039,1.347-2.693,2.02-4.959,2.02c-0.826,0-1.566-0.054-2.221-0.16c-0.652-0.106-1.207-0.233-1.66-0.38
				c-0.453-0.146-0.82-0.286-1.1-0.42s-0.461-0.226-0.541-0.28L125.575,25.978z"></path>
			<path class="clc-pattern-unit-letter" d="M121.235,25.217c-0.412,1.2-1.061,2.24-1.939,3.12c-0.881,0.88-2.006,1.574-3.381,2.08
				c-1.373,0.506-3.02,0.76-4.939,0.76c-1.334,0-2.494-0.087-3.48-0.26c-0.986-0.174-1.826-0.393-2.52-0.66l0.721-4.04
				c0.693,0.24,1.459,0.413,2.299,0.521c0.84,0.106,1.646,0.16,2.42,0.16c2.348,0,4.008-0.494,4.98-1.48
				c0.975-0.986,1.461-2.346,1.461-4.08c0-0.801-0.107-1.547-0.32-2.24s-0.561-1.286-1.041-1.779c-0.48-0.494-1.113-0.881-1.9-1.16
				c-0.785-0.28-1.766-0.42-2.939-0.42c-1.014,0-1.846,0.073-2.5,0.22c-0.652,0.146-1.246,0.313-1.779,0.5l-1.08-3.96
				c0.934-0.373,1.854-0.641,2.76-0.801s1.92-0.239,3.039-0.239c1.867,0,3.475,0.26,4.82,0.78c1.348,0.52,2.461,1.227,3.34,2.119
				c0.881,0.895,1.535,1.94,1.961,3.141c0.426,1.199,0.641,2.48,0.641,3.84C121.856,22.724,121.649,24.017,121.235,25.217z"></path>
			<path class="clc-pattern-unit-letter" d="M3.081,21.337c0-1.359,0.214-2.641,0.641-3.84c0.426-1.2,1.08-2.246,1.96-3.141c0.88-0.893,1.993-1.6,3.341-2.119
				c1.346-0.521,2.953-0.78,4.819-0.78c1.12,0,2.134,0.079,3.04,0.239s1.826,0.428,2.76,0.801l-1.08,3.96
				c-0.533-0.187-1.127-0.354-1.779-0.5c-0.654-0.146-1.487-0.22-2.5-0.22c-1.174,0-2.154,0.14-2.94,0.42
				c-0.787,0.279-1.42,0.666-1.899,1.16c-0.48,0.493-0.828,1.086-1.041,1.779s-0.32,1.439-0.32,2.24
				c0,1.734,0.486,3.094,1.461,4.08c0.973,0.986,2.633,1.48,4.98,1.48c0.772,0,1.579-0.054,2.42-0.16
				c0.84-0.107,1.605-0.28,2.299-0.521l0.721,4.04c-0.693,0.268-1.533,0.486-2.52,0.66c-0.987,0.173-2.147,0.26-3.48,0.26
				c-1.92,0-3.566-0.254-4.939-0.76c-1.375-0.506-2.5-1.2-3.381-2.08c-0.88-0.88-1.527-1.92-1.939-3.12
				C3.288,24.017,3.081,22.724,3.081,21.337z"></path>
			<path class="clc-pattern-unit-letter" d="M40.002,29.937c-0.08,0.055-0.261,0.146-0.54,0.28c-0.28,0.134-0.646,0.274-1.1,0.42
				c-0.454,0.146-1.008,0.273-1.66,0.38c-0.654,0.106-1.395,0.16-2.221,0.16c-2.267,0-3.92-0.673-4.959-2.02
				c-1.041-1.347-1.561-3.313-1.561-5.9V7.297h-5.2v-4.08h10.12v20.399c0,1.281,0.253,2.147,0.76,2.601
				c0.506,0.454,1.146,0.681,1.92,0.681c0.986,0,1.813-0.134,2.48-0.4c0.666-0.267,1.105-0.44,1.32-0.52L40.002,29.937z"></path>
			<path class="clc-pattern-unit-letter" d="M43.081,21.337c0-1.359,0.214-2.641,0.641-3.84c0.426-1.2,1.08-2.246,1.96-3.141c0.88-0.893,1.993-1.6,3.341-2.119
				c1.346-0.521,2.953-0.78,4.819-0.78c1.12,0,2.134,0.079,3.04,0.239s1.826,0.428,2.76,0.801l-1.08,3.96
				c-0.533-0.187-1.127-0.354-1.779-0.5c-0.654-0.146-1.487-0.22-2.5-0.22c-1.174,0-2.154,0.14-2.94,0.42
				c-0.787,0.279-1.42,0.666-1.899,1.16c-0.48,0.493-0.828,1.086-1.041,1.779s-0.32,1.439-0.32,2.24
				c0,1.734,0.486,3.094,1.461,4.08c0.973,0.986,2.633,1.48,4.98,1.48c0.772,0,1.579-0.054,2.42-0.16
				c0.84-0.107,1.605-0.28,2.299-0.521l0.721,4.04c-0.693,0.268-1.533,0.486-2.52,0.66c-0.987,0.173-2.147,0.26-3.48,0.26
				c-1.92,0-3.566-0.254-4.939-0.76c-1.375-0.506-2.5-1.2-3.381-2.08c-0.88-0.88-1.527-1.92-1.939-3.12
				C43.288,24.017,43.081,22.724,43.081,21.337z"></path>
			<path class="clc-pattern-unit-letter" d="M80.002,29.937c-0.08,0.055-0.261,0.146-0.54,0.28c-0.28,0.134-0.646,0.274-1.1,0.42
				c-0.454,0.146-1.008,0.273-1.66,0.38c-0.654,0.106-1.395,0.16-2.221,0.16c-2.267,0-3.92-0.673-4.959-2.02
				c-1.041-1.347-1.561-3.313-1.561-5.9V7.297h-5.2v-4.08h10.12v20.399c0,1.281,0.253,2.147,0.76,2.601
				c0.506,0.454,1.146,0.681,1.92,0.681c0.986,0,1.813-0.134,2.48-0.4c0.666-0.267,1.105-0.44,1.32-0.52L80.002,29.937z"></path>
			<path class="clc-pattern-unit-letter" d="M83.081,21.337c0-1.359,0.214-2.641,0.641-3.84c0.426-1.2,1.08-2.246,1.96-3.141c0.88-0.893,1.993-1.6,3.341-2.119
				c1.346-0.521,2.953-0.78,4.82-0.78c1.119,0,2.133,0.079,3.039,0.239s1.826,0.428,2.76,0.801l-1.08,3.96
				c-0.533-0.187-1.127-0.354-1.779-0.5c-0.654-0.146-1.486-0.22-2.5-0.22c-1.174,0-2.154,0.14-2.939,0.42
				c-0.787,0.279-1.42,0.666-1.9,1.16c-0.48,0.493-0.828,1.086-1.041,1.779s-0.32,1.439-0.32,2.24c0,1.734,0.486,3.094,1.461,4.08
				c0.973,0.986,2.633,1.48,4.98,1.48c0.773,0,1.58-0.054,2.42-0.16c0.84-0.107,1.605-0.28,2.299-0.521l0.721,4.04
				c-0.693,0.268-1.533,0.486-2.52,0.66c-0.986,0.173-2.146,0.26-3.48,0.26c-1.92,0-3.566-0.254-4.939-0.76
				c-1.375-0.506-2.5-1.2-3.381-2.08c-0.88-0.88-1.527-1.92-1.939-3.12C83.288,24.017,83.081,22.724,83.081,21.337z"></path>
			<path class="clc-pattern-unit-letter" d="M201.235,25.217c-0.412,1.2-1.061,2.24-1.939,3.12c-0.881,0.88-2.006,1.574-3.381,2.08
				c-1.373,0.506-3.02,0.76-4.939,0.76c-1.334,0-2.494-0.087-3.48-0.26c-0.986-0.174-1.826-0.393-2.52-0.66l0.721-4.04
				c0.693,0.24,1.459,0.413,2.299,0.521c0.84,0.106,1.646,0.16,2.42,0.16c2.348,0,4.008-0.494,4.98-1.48
				c0.975-0.986,1.461-2.346,1.461-4.08c0-0.801-0.107-1.547-0.32-2.24s-0.561-1.286-1.041-1.779c-0.48-0.494-1.113-0.881-1.9-1.16
				c-0.785-0.28-1.766-0.42-2.939-0.42c-1.014,0-1.846,0.073-2.5,0.22c-0.652,0.146-1.246,0.313-1.779,0.5l-1.08-3.96
				c0.934-0.373,1.854-0.641,2.76-0.801s1.92-0.239,3.039-0.239c1.867,0,3.475,0.26,4.82,0.78c1.348,0.52,2.461,1.227,3.34,2.119
				c0.881,0.895,1.535,1.94,1.961,3.141c0.426,1.199,0.641,2.48,0.641,3.84C201.856,22.724,201.649,24.017,201.235,25.217z"></path>
			<path class="clc-pattern-unit-letter" d="M165.575,25.978c0.215,0.079,0.654,0.253,1.32,0.52s1.494,0.4,2.48,0.4c0.773,0,1.414-0.227,1.92-0.681
				c0.506-0.453,0.76-1.319,0.76-2.601V3.217h10.119v4.08h-5.199v15.96c0,2.587-0.52,4.554-1.561,5.9
				c-1.039,1.347-2.693,2.02-4.959,2.02c-0.826,0-1.566-0.054-2.221-0.16c-0.652-0.106-1.207-0.233-1.66-0.38
				c-0.453-0.146-0.82-0.286-1.1-0.42s-0.461-0.226-0.541-0.28L165.575,25.978z"></path>
			<path class="clc-pattern-unit-letter" d="M161.235,25.217c-0.412,1.2-1.061,2.24-1.939,3.12c-0.881,0.88-2.006,1.574-3.381,2.08
				c-1.373,0.506-3.02,0.76-4.939,0.76c-1.334,0-2.494-0.087-3.48-0.26c-0.986-0.174-1.826-0.393-2.52-0.66l0.721-4.04
				c0.693,0.24,1.459,0.413,2.299,0.521c0.84,0.106,1.646,0.16,2.42,0.16c2.348,0,4.008-0.494,4.98-1.48
				c0.975-0.986,1.461-2.346,1.461-4.08c0-0.801-0.107-1.547-0.32-2.24s-0.561-1.286-1.041-1.779c-0.48-0.494-1.113-0.881-1.9-1.16
				c-0.785-0.28-1.766-0.42-2.939-0.42c-1.014,0-1.846,0.073-2.5,0.22c-0.652,0.146-1.246,0.313-1.779,0.5l-1.08-3.96
				c0.934-0.373,1.854-0.641,2.76-0.801s1.92-0.239,3.039-0.239c1.867,0,3.475,0.26,4.82,0.78c1.348,0.52,2.461,1.227,3.34,2.119
				c0.881,0.895,1.535,1.94,1.961,3.141c0.426,1.199,0.641,2.48,0.641,3.84C161.856,22.724,161.649,24.017,161.235,25.217z"></path>
			<path class="clc-pattern-unit-letter" d="M125.575,25.978c0.215,0.079,0.654,0.253,1.32,0.52s1.494,0.4,2.48,0.4c0.773,0,1.414-0.227,1.92-0.681
				c0.506-0.453,0.76-1.319,0.76-2.601V3.217h10.119v4.08h-5.199v15.96c0,2.587-0.52,4.554-1.561,5.9
				c-1.039,1.347-2.693,2.02-4.959,2.02c-0.826,0-1.566-0.054-2.221-0.16c-0.652-0.106-1.207-0.233-1.66-0.38
				c-0.453-0.146-0.82-0.286-1.1-0.42s-0.461-0.226-0.541-0.28L125.575,25.978z"></path>
			<path class="clc-pattern-unit-letter" d="M121.235,25.217c-0.412,1.2-1.061,2.24-1.939,3.12c-0.881,0.88-2.006,1.574-3.381,2.08
				c-1.373,0.506-3.02,0.76-4.939,0.76c-1.334,0-2.494-0.087-3.48-0.26c-0.986-0.174-1.826-0.393-2.52-0.66l0.721-4.04
				c0.693,0.24,1.459,0.413,2.299,0.521c0.84,0.106,1.646,0.16,2.42,0.16c2.348,0,4.008-0.494,4.98-1.48
				c0.975-0.986,1.461-2.346,1.461-4.08c0-0.801-0.107-1.547-0.32-2.24s-0.561-1.286-1.041-1.779c-0.48-0.494-1.113-0.881-1.9-1.16
				c-0.785-0.28-1.766-0.42-2.939-0.42c-1.014,0-1.846,0.073-2.5,0.22c-0.652,0.146-1.246,0.313-1.779,0.5l-1.08-3.96
				c0.934-0.373,1.854-0.641,2.76-0.801s1.92-0.239,3.039-0.239c1.867,0,3.475,0.26,4.82,0.78c1.348,0.52,2.461,1.227,3.34,2.119
				c0.881,0.895,1.535,1.94,1.961,3.141c0.426,1.199,0.641,2.48,0.641,3.84C121.856,22.724,121.649,24.017,121.235,25.217z"></path>
			<path class="clc-pattern-unit-letter" d="M20.002,68.807c-0.08,0.055-0.261,0.146-0.54,0.28c-0.28,0.134-0.646,0.274-1.1,0.42
				c-0.454,0.146-1.008,0.273-1.66,0.38c-0.654,0.106-1.395,0.16-2.221,0.16c-2.267,0-3.92-0.673-4.959-2.02
				c-1.041-1.347-1.561-3.313-1.561-5.9v-15.96h-5.2v-4.08h10.12v20.399c0,1.281,0.253,2.147,0.76,2.601
				c0.506,0.454,1.146,0.681,1.92,0.681c0.986,0,1.813-0.134,2.48-0.4c0.666-0.267,1.105-0.44,1.32-0.52L20.002,68.807z"></path>
			<path class="clc-pattern-unit-letter" d="M23.081,60.208c0-1.359,0.214-2.641,0.641-3.84c0.426-1.2,1.08-2.246,1.96-3.141c0.88-0.893,1.993-1.6,3.341-2.119
				c1.346-0.521,2.953-0.78,4.819-0.78c1.12,0,2.134,0.079,3.04,0.239s1.826,0.428,2.76,0.801l-1.08,3.96
				c-0.533-0.187-1.127-0.354-1.779-0.5c-0.654-0.146-1.487-0.22-2.5-0.22c-1.174,0-2.154,0.14-2.94,0.42
				c-0.787,0.279-1.42,0.666-1.899,1.16c-0.48,0.493-0.828,1.086-1.041,1.779s-0.32,1.439-0.32,2.24
				c0,1.734,0.486,3.094,1.461,4.08c0.973,0.986,2.633,1.48,4.98,1.48c0.772,0,1.579-0.054,2.42-0.16
				c0.84-0.107,1.605-0.28,2.299-0.521l0.721,4.04c-0.693,0.268-1.533,0.486-2.52,0.66c-0.987,0.173-2.147,0.26-3.48,0.26
				c-1.92,0-3.566-0.254-4.939-0.76c-1.375-0.506-2.5-1.2-3.381-2.08c-0.88-0.88-1.527-1.92-1.939-3.12
				C23.288,62.887,23.081,61.594,23.081,60.208z"></path>
			<path class="clc-pattern-unit-letter" d="M60.002,68.807c-0.08,0.055-0.261,0.146-0.54,0.28c-0.28,0.134-0.646,0.274-1.1,0.42
				c-0.454,0.146-1.008,0.273-1.66,0.38c-0.654,0.106-1.395,0.16-2.221,0.16c-2.267,0-3.92-0.673-4.959-2.02
				c-1.041-1.347-1.561-3.313-1.561-5.9v-15.96h-5.2v-4.08h10.12v20.399c0,1.281,0.253,2.147,0.76,2.601
				c0.506,0.454,1.146,0.681,1.92,0.681c0.986,0,1.813-0.134,2.48-0.4c0.666-0.267,1.105-0.44,1.32-0.52L60.002,68.807z"></path>
			<path class="clc-pattern-unit-letter" d="M63.081,60.208c0-1.359,0.214-2.641,0.641-3.84c0.426-1.2,1.08-2.246,1.96-3.141c0.88-0.893,1.993-1.6,3.341-2.119
				c1.346-0.521,2.953-0.78,4.819-0.78c1.12,0,2.134,0.079,3.04,0.239s1.826,0.428,2.76,0.801l-1.08,3.96
				c-0.533-0.187-1.127-0.354-1.779-0.5c-0.654-0.146-1.487-0.22-2.5-0.22c-1.174,0-2.154,0.14-2.94,0.42
				c-0.787,0.279-1.42,0.666-1.899,1.16c-0.48,0.493-0.828,1.086-1.041,1.779s-0.32,1.439-0.32,2.24
				c0,1.734,0.486,3.094,1.461,4.08c0.973,0.986,2.633,1.48,4.98,1.48c0.772,0,1.579-0.054,2.42-0.16
				c0.84-0.107,1.605-0.28,2.299-0.521l0.721,4.04c-0.693,0.268-1.533,0.486-2.52,0.66c-0.987,0.173-2.147,0.26-3.48,0.26
				c-1.92,0-3.566-0.254-4.939-0.76c-1.375-0.506-2.5-1.2-3.381-2.08c-0.88-0.88-1.527-1.92-1.939-3.12
				C63.288,62.887,63.081,61.594,63.081,60.208z"></path>
			<path class="clc-pattern-unit-letter" d="M100.003,68.807c-0.08,0.055-0.262,0.146-0.541,0.28s-0.646,0.274-1.1,0.42c-0.453,0.146-1.008,0.273-1.66,0.38
				c-0.654,0.106-1.395,0.16-2.221,0.16c-2.266,0-3.92-0.673-4.959-2.02c-1.041-1.347-1.561-3.313-1.561-5.9v-15.96h-5.2v-4.08
				h10.12v20.399c0,1.281,0.254,2.147,0.76,2.601c0.506,0.454,1.146,0.681,1.92,0.681c0.986,0,1.814-0.134,2.48-0.4
				s1.105-0.44,1.32-0.52L100.003,68.807z"></path>
			<path class="clc-pattern-unit-letter" d="M185.575,64.848c0.215,0.079,0.654,0.253,1.32,0.52s1.494,0.4,2.48,0.4c0.773,0,1.414-0.227,1.92-0.681
				c0.506-0.453,0.76-1.319,0.76-2.601V42.087h10.119v4.08h-5.199v15.96c0,2.587-0.52,4.554-1.561,5.9
				c-1.039,1.347-2.693,2.02-4.959,2.02c-0.826,0-1.566-0.054-2.221-0.16c-0.652-0.106-1.207-0.233-1.66-0.38
				c-0.453-0.146-0.82-0.286-1.1-0.42s-0.461-0.226-0.541-0.28L185.575,64.848z"></path>
			<path class="clc-pattern-unit-letter" d="M181.235,64.087c-0.412,1.2-1.061,2.24-1.939,3.12c-0.881,0.88-2.006,1.574-3.381,2.08
				c-1.373,0.506-3.02,0.76-4.939,0.76c-1.334,0-2.494-0.087-3.48-0.26c-0.986-0.174-1.826-0.393-2.52-0.66l0.721-4.04
				c0.693,0.24,1.459,0.413,2.299,0.521c0.84,0.106,1.646,0.16,2.42,0.16c2.348,0,4.008-0.494,4.98-1.48
				c0.975-0.986,1.461-2.346,1.461-4.08c0-0.801-0.107-1.547-0.32-2.24s-0.561-1.286-1.041-1.779c-0.48-0.494-1.113-0.881-1.9-1.16
				c-0.785-0.28-1.766-0.42-2.939-0.42c-1.014,0-1.846,0.073-2.5,0.22c-0.652,0.146-1.246,0.313-1.779,0.5l-1.08-3.96
				c0.934-0.373,1.854-0.641,2.76-0.801s1.92-0.239,3.039-0.239c1.867,0,3.475,0.26,4.82,0.78c1.348,0.52,2.461,1.227,3.34,2.119
				c0.881,0.895,1.535,1.94,1.961,3.141c0.426,1.199,0.641,2.48,0.641,3.84C181.856,61.594,181.649,62.887,181.235,64.087z"></path>
			<path class="clc-pattern-unit-letter" d="M145.575,64.848c0.215,0.079,0.654,0.253,1.32,0.52s1.494,0.4,2.48,0.4c0.773,0,1.414-0.227,1.92-0.681
				c0.506-0.453,0.76-1.319,0.76-2.601V42.087h10.119v4.08h-5.199v15.96c0,2.587-0.52,4.554-1.561,5.9
				c-1.039,1.347-2.693,2.02-4.959,2.02c-0.826,0-1.566-0.054-2.221-0.16c-0.652-0.106-1.207-0.233-1.66-0.38
				c-0.453-0.146-0.82-0.286-1.1-0.42s-0.461-0.226-0.541-0.28L145.575,64.848z"></path>
			<path class="clc-pattern-unit-letter" d="M141.235,64.087c-0.412,1.2-1.061,2.24-1.939,3.12c-0.881,0.88-2.006,1.574-3.381,2.08
				c-1.373,0.506-3.02,0.76-4.939,0.76c-1.334,0-2.494-0.087-3.48-0.26c-0.986-0.174-1.826-0.393-2.52-0.66l0.721-4.04
				c0.693,0.24,1.459,0.413,2.299,0.521c0.84,0.106,1.646,0.16,2.42,0.16c2.348,0,4.008-0.494,4.98-1.48
				c0.975-0.986,1.461-2.346,1.461-4.08c0-0.801-0.107-1.547-0.32-2.24s-0.561-1.286-1.041-1.779c-0.48-0.494-1.113-0.881-1.9-1.16
				c-0.785-0.28-1.766-0.42-2.939-0.42c-1.014,0-1.846,0.073-2.5,0.22c-0.652,0.146-1.246,0.313-1.779,0.5l-1.08-3.96
				c0.934-0.373,1.854-0.641,2.76-0.801s1.92-0.239,3.039-0.239c1.867,0,3.475,0.26,4.82,0.78c1.348,0.52,2.461,1.227,3.34,2.119
				c0.881,0.895,1.535,1.94,1.961,3.141c0.426,1.199,0.641,2.48,0.641,3.84C141.856,61.594,141.649,62.887,141.235,64.087z"></path>
			<path class="clc-pattern-unit-letter" d="M105.575,64.848c0.215,0.079,0.654,0.253,1.32,0.52s1.494,0.4,2.48,0.4c0.773,0,1.414-0.227,1.92-0.681
				c0.506-0.453,0.76-1.319,0.76-2.601V42.087h10.119v4.08h-5.199v15.96c0,2.587-0.52,4.554-1.561,5.9
				c-1.039,1.347-2.693,2.02-4.959,2.02c-0.826,0-1.566-0.054-2.221-0.16c-0.652-0.106-1.207-0.233-1.66-0.38
				c-0.453-0.146-0.82-0.286-1.1-0.42s-0.461-0.226-0.541-0.28L105.575,64.848z"></path>
			<path class="clc-pattern-unit-letter" d="M20.002,68.807c-0.08,0.055-0.261,0.146-0.54,0.28c-0.28,0.134-0.646,0.274-1.1,0.42
				c-0.454,0.146-1.008,0.273-1.66,0.38c-0.654,0.106-1.395,0.16-2.221,0.16c-2.267,0-3.92-0.673-4.959-2.02
				c-1.041-1.347-1.561-3.313-1.561-5.9v-15.96h-5.2v-4.08h10.12v20.399c0,1.281,0.253,2.147,0.76,2.601
				c0.506,0.454,1.146,0.681,1.92,0.681c0.986,0,1.813-0.134,2.48-0.4c0.666-0.267,1.105-0.44,1.32-0.52L20.002,68.807z"></path>
			<path class="clc-pattern-unit-letter" d="M23.081,60.208c0-1.359,0.214-2.641,0.641-3.84c0.426-1.2,1.08-2.246,1.96-3.141c0.88-0.893,1.993-1.6,3.341-2.119
				c1.346-0.521,2.953-0.78,4.819-0.78c1.12,0,2.134,0.079,3.04,0.239s1.826,0.428,2.76,0.801l-1.08,3.96
				c-0.533-0.187-1.127-0.354-1.779-0.5c-0.654-0.146-1.487-0.22-2.5-0.22c-1.174,0-2.154,0.14-2.94,0.42
				c-0.787,0.279-1.42,0.666-1.899,1.16c-0.48,0.493-0.828,1.086-1.041,1.779s-0.32,1.439-0.32,2.24
				c0,1.734,0.486,3.094,1.461,4.08c0.973,0.986,2.633,1.48,4.98,1.48c0.772,0,1.579-0.054,2.42-0.16
				c0.84-0.107,1.605-0.28,2.299-0.521l0.721,4.04c-0.693,0.268-1.533,0.486-2.52,0.66c-0.987,0.173-2.147,0.26-3.48,0.26
				c-1.92,0-3.566-0.254-4.939-0.76c-1.375-0.506-2.5-1.2-3.381-2.08c-0.88-0.88-1.527-1.92-1.939-3.12
				C23.288,62.887,23.081,61.594,23.081,60.208z"></path>
			<path class="clc-pattern-unit-letter" d="M60.002,68.807c-0.08,0.055-0.261,0.146-0.54,0.28c-0.28,0.134-0.646,0.274-1.1,0.42
				c-0.454,0.146-1.008,0.273-1.66,0.38c-0.654,0.106-1.395,0.16-2.221,0.16c-2.267,0-3.92-0.673-4.959-2.02
				c-1.041-1.347-1.561-3.313-1.561-5.9v-15.96h-5.2v-4.08h10.12v20.399c0,1.281,0.253,2.147,0.76,2.601
				c0.506,0.454,1.146,0.681,1.92,0.681c0.986,0,1.813-0.134,2.48-0.4c0.666-0.267,1.105-0.44,1.32-0.52L60.002,68.807z"></path>
			<path class="clc-pattern-unit-letter" d="M63.081,60.208c0-1.359,0.214-2.641,0.641-3.84c0.426-1.2,1.08-2.246,1.96-3.141c0.88-0.893,1.993-1.6,3.341-2.119
				c1.346-0.521,2.953-0.78,4.819-0.78c1.12,0,2.134,0.079,3.04,0.239s1.826,0.428,2.76,0.801l-1.08,3.96
				c-0.533-0.187-1.127-0.354-1.779-0.5c-0.654-0.146-1.487-0.22-2.5-0.22c-1.174,0-2.154,0.14-2.94,0.42
				c-0.787,0.279-1.42,0.666-1.899,1.16c-0.48,0.493-0.828,1.086-1.041,1.779s-0.32,1.439-0.32,2.24
				c0,1.734,0.486,3.094,1.461,4.08c0.973,0.986,2.633,1.48,4.98,1.48c0.772,0,1.579-0.054,2.42-0.16
				c0.84-0.107,1.605-0.28,2.299-0.521l0.721,4.04c-0.693,0.268-1.533,0.486-2.52,0.66c-0.987,0.173-2.147,0.26-3.48,0.26
				c-1.92,0-3.566-0.254-4.939-0.76c-1.375-0.506-2.5-1.2-3.381-2.08c-0.88-0.88-1.527-1.92-1.939-3.12
				C63.288,62.887,63.081,61.594,63.081,60.208z"></path>
			<path class="clc-pattern-unit-letter" d="M100.003,68.807c-0.08,0.055-0.262,0.146-0.541,0.28s-0.646,0.274-1.1,0.42c-0.453,0.146-1.008,0.273-1.66,0.38
				c-0.654,0.106-1.395,0.16-2.221,0.16c-2.266,0-3.92-0.673-4.959-2.02c-1.041-1.347-1.561-3.313-1.561-5.9v-15.96h-5.2v-4.08
				h10.12v20.399c0,1.281,0.254,2.147,0.76,2.601c0.506,0.454,1.146,0.681,1.92,0.681c0.986,0,1.814-0.134,2.48-0.4
				s1.105-0.44,1.32-0.52L100.003,68.807z"></path>
			<path class="clc-pattern-unit-letter" d="M185.575,64.848c0.215,0.079,0.654,0.253,1.32,0.52s1.494,0.4,2.48,0.4c0.773,0,1.414-0.227,1.92-0.681
				c0.506-0.453,0.76-1.319,0.76-2.601V42.087h10.119v4.08h-5.199v15.96c0,2.587-0.52,4.554-1.561,5.9
				c-1.039,1.347-2.693,2.02-4.959,2.02c-0.826,0-1.566-0.054-2.221-0.16c-0.652-0.106-1.207-0.233-1.66-0.38
				c-0.453-0.146-0.82-0.286-1.1-0.42s-0.461-0.226-0.541-0.28L185.575,64.848z"></path>
			<path class="clc-pattern-unit-letter" d="M181.235,64.087c-0.412,1.2-1.061,2.24-1.939,3.12c-0.881,0.88-2.006,1.574-3.381,2.08
				c-1.373,0.506-3.02,0.76-4.939,0.76c-1.334,0-2.494-0.087-3.48-0.26c-0.986-0.174-1.826-0.393-2.52-0.66l0.721-4.04
				c0.693,0.24,1.459,0.413,2.299,0.521c0.84,0.106,1.646,0.16,2.42,0.16c2.348,0,4.008-0.494,4.98-1.48
				c0.975-0.986,1.461-2.346,1.461-4.08c0-0.801-0.107-1.547-0.32-2.24s-0.561-1.286-1.041-1.779c-0.48-0.494-1.113-0.881-1.9-1.16
				c-0.785-0.28-1.766-0.42-2.939-0.42c-1.014,0-1.846,0.073-2.5,0.22c-0.652,0.146-1.246,0.313-1.779,0.5l-1.08-3.96
				c0.934-0.373,1.854-0.641,2.76-0.801s1.92-0.239,3.039-0.239c1.867,0,3.475,0.26,4.82,0.78c1.348,0.52,2.461,1.227,3.34,2.119
				c0.881,0.895,1.535,1.94,1.961,3.141c0.426,1.199,0.641,2.48,0.641,3.84C181.856,61.594,181.649,62.887,181.235,64.087z"></path>
			<path class="clc-pattern-unit-letter" d="M145.575,64.848c0.215,0.079,0.654,0.253,1.32,0.52s1.494,0.4,2.48,0.4c0.773,0,1.414-0.227,1.92-0.681
				c0.506-0.453,0.76-1.319,0.76-2.601V42.087h10.119v4.08h-5.199v15.96c0,2.587-0.52,4.554-1.561,5.9
				c-1.039,1.347-2.693,2.02-4.959,2.02c-0.826,0-1.566-0.054-2.221-0.16c-0.652-0.106-1.207-0.233-1.66-0.38
				c-0.453-0.146-0.82-0.286-1.1-0.42s-0.461-0.226-0.541-0.28L145.575,64.848z"></path>
			<path class="clc-pattern-unit-letter" d="M141.235,64.087c-0.412,1.2-1.061,2.24-1.939,3.12c-0.881,0.88-2.006,1.574-3.381,2.08
				c-1.373,0.506-3.02,0.76-4.939,0.76c-1.334,0-2.494-0.087-3.48-0.26c-0.986-0.174-1.826-0.393-2.52-0.66l0.721-4.04
				c0.693,0.24,1.459,0.413,2.299,0.521c0.84,0.106,1.646,0.16,2.42,0.16c2.348,0,4.008-0.494,4.98-1.48
				c0.975-0.986,1.461-2.346,1.461-4.08c0-0.801-0.107-1.547-0.32-2.24s-0.561-1.286-1.041-1.779c-0.48-0.494-1.113-0.881-1.9-1.16
				c-0.785-0.28-1.766-0.42-2.939-0.42c-1.014,0-1.846,0.073-2.5,0.22c-0.652,0.146-1.246,0.313-1.779,0.5l-1.08-3.96
				c0.934-0.373,1.854-0.641,2.76-0.801s1.92-0.239,3.039-0.239c1.867,0,3.475,0.26,4.82,0.78c1.348,0.52,2.461,1.227,3.34,2.119
				c0.881,0.895,1.535,1.94,1.961,3.141c0.426,1.199,0.641,2.48,0.641,3.84C141.856,61.594,141.649,62.887,141.235,64.087z"></path>
			<path class="clc-pattern-unit-letter" d="M105.575,64.848c0.215,0.079,0.654,0.253,1.32,0.52s1.494,0.4,2.48,0.4c0.773,0,1.414-0.227,1.92-0.681
				c0.506-0.453,0.76-1.319,0.76-2.601V42.087h10.119v4.08h-5.199v15.96c0,2.587-0.52,4.554-1.561,5.9
				c-1.039,1.347-2.693,2.02-4.959,2.02c-0.826,0-1.566-0.054-2.221-0.16c-0.652-0.106-1.207-0.233-1.66-0.38
				c-0.453-0.146-0.82-0.286-1.1-0.42s-0.461-0.226-0.541-0.28L105.575,64.848z"></path>
			<path class="clc-pattern-unit-letter" d="M3.702,125.789c0.412-1.2,1.06-2.24,1.939-3.12c0.881-0.88,2.006-1.574,3.381-2.08c1.373-0.506,3.02-0.76,4.939-0.76
				c1.333,0,2.493,0.087,3.48,0.26c0.986,0.174,1.826,0.393,2.52,0.66l-0.721,4.04c-0.693-0.24-1.459-0.413-2.299-0.521
				c-0.841-0.106-1.647-0.16-2.42-0.16c-2.348,0-4.008,0.494-4.98,1.48c-0.975,0.986-1.461,2.346-1.461,4.08
				c0,0.801,0.107,1.547,0.32,2.24s0.561,1.286,1.041,1.779c0.479,0.494,1.112,0.881,1.899,1.16c0.786,0.28,1.767,0.42,2.94,0.42
				c1.013,0,1.846-0.073,2.5-0.22c0.652-0.146,1.246-0.313,1.779-0.5l1.08,3.96c-0.934,0.373-1.854,0.641-2.76,0.801
				s-1.92,0.239-3.04,0.239c-1.866,0-3.474-0.26-4.819-0.78c-1.348-0.52-2.461-1.227-3.341-2.119
				c-0.88-0.895-1.534-1.94-1.96-3.141c-0.427-1.199-0.641-2.48-0.641-3.84C3.081,128.282,3.288,126.989,3.702,125.789z"></path>
			<path class="clc-pattern-unit-letter" d="M39.362,125.028c-0.215-0.079-0.654-0.253-1.32-0.52c-0.667-0.267-1.494-0.4-2.48-0.4c-0.773,0-1.414,0.227-1.92,0.681
				c-0.507,0.453-0.76,1.319-0.76,2.601v20.399h-10.12v-4.08h5.2v-15.96c0-2.587,0.52-4.554,1.561-5.9
				c1.039-1.347,2.692-2.02,4.959-2.02c0.826,0,1.566,0.054,2.221,0.16c0.652,0.106,1.206,0.233,1.66,0.38
				c0.453,0.146,0.819,0.286,1.1,0.42c0.279,0.134,0.46,0.226,0.54,0.28L39.362,125.028z"></path>
			<path class="clc-pattern-unit-letter" d="M43.702,125.789c0.412-1.2,1.06-2.24,1.939-3.12c0.881-0.88,2.006-1.574,3.381-2.08c1.373-0.506,3.02-0.76,4.939-0.76
				c1.333,0,2.493,0.087,3.48,0.26c0.986,0.174,1.826,0.393,2.52,0.66l-0.721,4.04c-0.693-0.24-1.459-0.413-2.299-0.521
				c-0.841-0.106-1.647-0.16-2.42-0.16c-2.348,0-4.008,0.494-4.98,1.48c-0.975,0.986-1.461,2.346-1.461,4.08
				c0,0.801,0.107,1.547,0.32,2.24s0.561,1.286,1.041,1.779c0.479,0.494,1.112,0.881,1.899,1.16c0.786,0.28,1.767,0.42,2.94,0.42
				c1.013,0,1.846-0.073,2.5-0.22c0.652-0.146,1.246-0.313,1.779-0.5l1.08,3.96c-0.934,0.373-1.854,0.641-2.76,0.801
				s-1.92,0.239-3.04,0.239c-1.866,0-3.474-0.26-4.819-0.78c-1.348-0.52-2.461-1.227-3.341-2.119
				c-0.88-0.895-1.534-1.94-1.96-3.141c-0.427-1.199-0.641-2.48-0.641-3.84C43.081,128.282,43.288,126.989,43.702,125.789z"></path>
			<path class="clc-pattern-unit-letter" d="M79.362,125.028c-0.215-0.079-0.654-0.253-1.32-0.52c-0.667-0.267-1.494-0.4-2.48-0.4c-0.773,0-1.414,0.227-1.92,0.681
				c-0.507,0.453-0.76,1.319-0.76,2.601v20.399h-10.12v-4.08h5.2v-15.96c0-2.587,0.52-4.554,1.561-5.9
				c1.039-1.347,2.692-2.02,4.959-2.02c0.826,0,1.566,0.054,2.221,0.16c0.652,0.106,1.206,0.233,1.66,0.38
				c0.453,0.146,0.819,0.286,1.1,0.42c0.279,0.134,0.46,0.226,0.54,0.28L79.362,125.028z"></path>
			<path class="clc-pattern-unit-letter" d="M83.702,125.789c0.412-1.2,1.06-2.24,1.939-3.12c0.881-0.88,2.006-1.574,3.381-2.08c1.373-0.506,3.02-0.76,4.939-0.76
				c1.334,0,2.494,0.087,3.48,0.26c0.986,0.174,1.826,0.393,2.52,0.66l-0.721,4.04c-0.693-0.24-1.459-0.413-2.299-0.521
				c-0.84-0.106-1.646-0.16-2.42-0.16c-2.348,0-4.008,0.494-4.98,1.48c-0.975,0.986-1.461,2.346-1.461,4.08
				c0,0.801,0.107,1.547,0.32,2.24s0.561,1.286,1.041,1.779c0.48,0.494,1.113,0.881,1.9,1.16c0.785,0.28,1.766,0.42,2.939,0.42
				c1.014,0,1.846-0.073,2.5-0.22c0.652-0.146,1.246-0.313,1.779-0.5l1.08,3.96c-0.934,0.373-1.854,0.641-2.76,0.801
				s-1.92,0.239-3.039,0.239c-1.867,0-3.475-0.26-4.82-0.78c-1.348-0.52-2.461-1.227-3.341-2.119
				c-0.88-0.895-1.534-1.94-1.96-3.141c-0.427-1.199-0.641-2.48-0.641-3.84C83.081,128.282,83.288,126.989,83.702,125.789z"></path>
			<path class="clc-pattern-unit-letter" d="M201.856,129.668c0,1.359-0.215,2.641-0.641,3.84c-0.426,1.2-1.08,2.246-1.961,3.141c-0.879,0.893-1.992,1.6-3.34,2.119
				c-1.346,0.521-2.953,0.78-4.82,0.78c-1.119,0-2.133-0.079-3.039-0.239s-1.826-0.428-2.76-0.801l1.08-3.96
				c0.533,0.187,1.127,0.354,1.779,0.5c0.654,0.146,1.486,0.22,2.5,0.22c1.174,0,2.154-0.14,2.939-0.42
				c0.787-0.279,1.42-0.666,1.9-1.16c0.48-0.493,0.828-1.086,1.041-1.779s0.32-1.439,0.32-2.24c0-1.734-0.486-3.094-1.461-4.08
				c-0.973-0.986-2.633-1.48-4.98-1.48c-0.773,0-1.58,0.054-2.42,0.16c-0.84,0.107-1.605,0.28-2.299,0.521l-0.721-4.04
				c0.693-0.268,1.533-0.486,2.52-0.66c0.986-0.173,2.146-0.26,3.48-0.26c1.92,0,3.566,0.254,4.939,0.76
				c1.375,0.506,2.5,1.2,3.381,2.08c0.879,0.88,1.527,1.92,1.939,3.12C201.649,126.989,201.856,128.282,201.856,129.668z"></path>
			<path class="clc-pattern-unit-letter" d="M164.935,121.069c0.08-0.055,0.262-0.146,0.541-0.28s0.646-0.274,1.1-0.42c0.453-0.146,1.008-0.273,1.66-0.38
				c0.654-0.106,1.395-0.16,2.221-0.16c2.266,0,3.92,0.673,4.959,2.02c1.041,1.347,1.561,3.313,1.561,5.9v15.96h5.199v4.08h-10.119
				v-20.399c0-1.281-0.254-2.147-0.76-2.601c-0.506-0.454-1.146-0.681-1.92-0.681c-0.986,0-1.814,0.134-2.48,0.4
				s-1.105,0.44-1.32,0.52L164.935,121.069z"></path>
			<path class="clc-pattern-unit-letter" d="M161.856,129.668c0,1.359-0.215,2.641-0.641,3.84c-0.426,1.2-1.08,2.246-1.961,3.141c-0.879,0.893-1.992,1.6-3.34,2.119
				c-1.346,0.521-2.953,0.78-4.82,0.78c-1.119,0-2.133-0.079-3.039-0.239s-1.826-0.428-2.76-0.801l1.08-3.96
				c0.533,0.187,1.127,0.354,1.779,0.5c0.654,0.146,1.486,0.22,2.5,0.22c1.174,0,2.154-0.14,2.939-0.42
				c0.787-0.279,1.42-0.666,1.9-1.16c0.48-0.493,0.828-1.086,1.041-1.779s0.32-1.439,0.32-2.24c0-1.734-0.486-3.094-1.461-4.08
				c-0.973-0.986-2.633-1.48-4.98-1.48c-0.773,0-1.58,0.054-2.42,0.16c-0.84,0.107-1.605,0.28-2.299,0.521l-0.721-4.04
				c0.693-0.268,1.533-0.486,2.52-0.66c0.986-0.173,2.146-0.26,3.48-0.26c1.92,0,3.566,0.254,4.939,0.76
				c1.375,0.506,2.5,1.2,3.381,2.08c0.879,0.88,1.527,1.92,1.939,3.12C161.649,126.989,161.856,128.282,161.856,129.668z"></path>
			<path class="clc-pattern-unit-letter" d="M124.935,121.069c0.08-0.055,0.262-0.146,0.541-0.28s0.646-0.274,1.1-0.42c0.453-0.146,1.008-0.273,1.66-0.38
				c0.654-0.106,1.395-0.16,2.221-0.16c2.266,0,3.92,0.673,4.959,2.02c1.041,1.347,1.561,3.313,1.561,5.9v15.96h5.199v4.08h-10.119
				v-20.399c0-1.281-0.254-2.147-0.76-2.601c-0.506-0.454-1.146-0.681-1.92-0.681c-0.986,0-1.814,0.134-2.48,0.4
				s-1.105,0.44-1.32,0.52L124.935,121.069z"></path>
			<path class="clc-pattern-unit-letter" d="M121.856,129.668c0,1.359-0.215,2.641-0.641,3.84c-0.426,1.2-1.08,2.246-1.961,3.141c-0.879,0.893-1.992,1.6-3.34,2.119
				c-1.346,0.521-2.953,0.78-4.82,0.78c-1.119,0-2.133-0.079-3.039-0.239s-1.826-0.428-2.76-0.801l1.08-3.96
				c0.533,0.187,1.127,0.354,1.779,0.5c0.654,0.146,1.486,0.22,2.5,0.22c1.174,0,2.154-0.14,2.939-0.42
				c0.787-0.279,1.42-0.666,1.9-1.16c0.48-0.493,0.828-1.086,1.041-1.779s0.32-1.439,0.32-2.24c0-1.734-0.486-3.094-1.461-4.08
				c-0.973-0.986-2.633-1.48-4.98-1.48c-0.773,0-1.58,0.054-2.42,0.16c-0.84,0.107-1.605,0.28-2.299,0.521l-0.721-4.04
				c0.693-0.268,1.533-0.486,2.52-0.66c0.986-0.173,2.146-0.26,3.48-0.26c1.92,0,3.566,0.254,4.939,0.76
				c1.375,0.506,2.5,1.2,3.381,2.08c0.879,0.88,1.527,1.92,1.939,3.12C121.649,126.989,121.856,128.282,121.856,129.668z"></path>
			<path class="clc-pattern-unit-letter" d="M3.702,125.789c0.412-1.2,1.06-2.24,1.939-3.12c0.881-0.88,2.006-1.574,3.381-2.08c1.373-0.506,3.02-0.76,4.939-0.76
				c1.333,0,2.493,0.087,3.48,0.26c0.986,0.174,1.826,0.393,2.52,0.66l-0.721,4.04c-0.693-0.24-1.459-0.413-2.299-0.521
				c-0.841-0.106-1.647-0.16-2.42-0.16c-2.348,0-4.008,0.494-4.98,1.48c-0.975,0.986-1.461,2.346-1.461,4.08
				c0,0.801,0.107,1.547,0.32,2.24s0.561,1.286,1.041,1.779c0.479,0.494,1.112,0.881,1.899,1.16c0.786,0.28,1.767,0.42,2.94,0.42
				c1.013,0,1.846-0.073,2.5-0.22c0.652-0.146,1.246-0.313,1.779-0.5l1.08,3.96c-0.934,0.373-1.854,0.641-2.76,0.801
				s-1.92,0.239-3.04,0.239c-1.866,0-3.474-0.26-4.819-0.78c-1.348-0.52-2.461-1.227-3.341-2.119
				c-0.88-0.895-1.534-1.94-1.96-3.141c-0.427-1.199-0.641-2.48-0.641-3.84C3.081,128.282,3.288,126.989,3.702,125.789z"></path>
			<path class="clc-pattern-unit-letter" d="M39.362,125.028c-0.215-0.079-0.654-0.253-1.32-0.52c-0.667-0.267-1.494-0.4-2.48-0.4c-0.773,0-1.414,0.227-1.92,0.681
				c-0.507,0.453-0.76,1.319-0.76,2.601v20.399h-10.12v-4.08h5.2v-15.96c0-2.587,0.52-4.554,1.561-5.9
				c1.039-1.347,2.692-2.02,4.959-2.02c0.826,0,1.566,0.054,2.221,0.16c0.652,0.106,1.206,0.233,1.66,0.38
				c0.453,0.146,0.819,0.286,1.1,0.42c0.279,0.134,0.46,0.226,0.54,0.28L39.362,125.028z"></path>
			<path class="clc-pattern-unit-letter" d="M43.702,125.789c0.412-1.2,1.06-2.24,1.939-3.12c0.881-0.88,2.006-1.574,3.381-2.08c1.373-0.506,3.02-0.76,4.939-0.76
				c1.333,0,2.493,0.087,3.48,0.26c0.986,0.174,1.826,0.393,2.52,0.66l-0.721,4.04c-0.693-0.24-1.459-0.413-2.299-0.521
				c-0.841-0.106-1.647-0.16-2.42-0.16c-2.348,0-4.008,0.494-4.98,1.48c-0.975,0.986-1.461,2.346-1.461,4.08
				c0,0.801,0.107,1.547,0.32,2.24s0.561,1.286,1.041,1.779c0.479,0.494,1.112,0.881,1.899,1.16c0.786,0.28,1.767,0.42,2.94,0.42
				c1.013,0,1.846-0.073,2.5-0.22c0.652-0.146,1.246-0.313,1.779-0.5l1.08,3.96c-0.934,0.373-1.854,0.641-2.76,0.801
				s-1.92,0.239-3.04,0.239c-1.866,0-3.474-0.26-4.819-0.78c-1.348-0.52-2.461-1.227-3.341-2.119
				c-0.88-0.895-1.534-1.94-1.96-3.141c-0.427-1.199-0.641-2.48-0.641-3.84C43.081,128.282,43.288,126.989,43.702,125.789z"></path>
			<path class="clc-pattern-unit-letter" d="M79.362,125.028c-0.215-0.079-0.654-0.253-1.32-0.52c-0.667-0.267-1.494-0.4-2.48-0.4c-0.773,0-1.414,0.227-1.92,0.681
				c-0.507,0.453-0.76,1.319-0.76,2.601v20.399h-10.12v-4.08h5.2v-15.96c0-2.587,0.52-4.554,1.561-5.9
				c1.039-1.347,2.692-2.02,4.959-2.02c0.826,0,1.566,0.054,2.221,0.16c0.652,0.106,1.206,0.233,1.66,0.38
				c0.453,0.146,0.819,0.286,1.1,0.42c0.279,0.134,0.46,0.226,0.54,0.28L79.362,125.028z"></path>
			<path class="clc-pattern-unit-letter" d="M83.702,125.789c0.412-1.2,1.06-2.24,1.939-3.12c0.881-0.88,2.006-1.574,3.381-2.08c1.373-0.506,3.02-0.76,4.939-0.76
				c1.334,0,2.494,0.087,3.48,0.26c0.986,0.174,1.826,0.393,2.52,0.66l-0.721,4.04c-0.693-0.24-1.459-0.413-2.299-0.521
				c-0.84-0.106-1.646-0.16-2.42-0.16c-2.348,0-4.008,0.494-4.98,1.48c-0.975,0.986-1.461,2.346-1.461,4.08
				c0,0.801,0.107,1.547,0.32,2.24s0.561,1.286,1.041,1.779c0.48,0.494,1.113,0.881,1.9,1.16c0.785,0.28,1.766,0.42,2.939,0.42
				c1.014,0,1.846-0.073,2.5-0.22c0.652-0.146,1.246-0.313,1.779-0.5l1.08,3.96c-0.934,0.373-1.854,0.641-2.76,0.801
				s-1.92,0.239-3.039,0.239c-1.867,0-3.475-0.26-4.82-0.78c-1.348-0.52-2.461-1.227-3.341-2.119
				c-0.88-0.895-1.534-1.94-1.96-3.141c-0.427-1.199-0.641-2.48-0.641-3.84C83.081,128.282,83.288,126.989,83.702,125.789z"></path>
			<path class="clc-pattern-unit-letter" d="M201.856,129.668c0,1.359-0.215,2.641-0.641,3.84c-0.426,1.2-1.08,2.246-1.961,3.141c-0.879,0.893-1.992,1.6-3.34,2.119
				c-1.346,0.521-2.953,0.78-4.82,0.78c-1.119,0-2.133-0.079-3.039-0.239s-1.826-0.428-2.76-0.801l1.08-3.96
				c0.533,0.187,1.127,0.354,1.779,0.5c0.654,0.146,1.486,0.22,2.5,0.22c1.174,0,2.154-0.14,2.939-0.42
				c0.787-0.279,1.42-0.666,1.9-1.16c0.48-0.493,0.828-1.086,1.041-1.779s0.32-1.439,0.32-2.24c0-1.734-0.486-3.094-1.461-4.08
				c-0.973-0.986-2.633-1.48-4.98-1.48c-0.773,0-1.58,0.054-2.42,0.16c-0.84,0.107-1.605,0.28-2.299,0.521l-0.721-4.04
				c0.693-0.268,1.533-0.486,2.52-0.66c0.986-0.173,2.146-0.26,3.48-0.26c1.92,0,3.566,0.254,4.939,0.76
				c1.375,0.506,2.5,1.2,3.381,2.08c0.879,0.88,1.527,1.92,1.939,3.12C201.649,126.989,201.856,128.282,201.856,129.668z"></path>
			<path class="clc-pattern-unit-letter" d="M164.935,121.069c0.08-0.055,0.262-0.146,0.541-0.28s0.646-0.274,1.1-0.42c0.453-0.146,1.008-0.273,1.66-0.38
				c0.654-0.106,1.395-0.16,2.221-0.16c2.266,0,3.92,0.673,4.959,2.02c1.041,1.347,1.561,3.313,1.561,5.9v15.96h5.199v4.08h-10.119
				v-20.399c0-1.281-0.254-2.147-0.76-2.601c-0.506-0.454-1.146-0.681-1.92-0.681c-0.986,0-1.814,0.134-2.48,0.4
				s-1.105,0.44-1.32,0.52L164.935,121.069z"></path>
			<path class="clc-pattern-unit-letter" d="M161.856,129.668c0,1.359-0.215,2.641-0.641,3.84c-0.426,1.2-1.08,2.246-1.961,3.141c-0.879,0.893-1.992,1.6-3.34,2.119
				c-1.346,0.521-2.953,0.78-4.82,0.78c-1.119,0-2.133-0.079-3.039-0.239s-1.826-0.428-2.76-0.801l1.08-3.96
				c0.533,0.187,1.127,0.354,1.779,0.5c0.654,0.146,1.486,0.22,2.5,0.22c1.174,0,2.154-0.14,2.939-0.42
				c0.787-0.279,1.42-0.666,1.9-1.16c0.48-0.493,0.828-1.086,1.041-1.779s0.32-1.439,0.32-2.24c0-1.734-0.486-3.094-1.461-4.08
				c-0.973-0.986-2.633-1.48-4.98-1.48c-0.773,0-1.58,0.054-2.42,0.16c-0.84,0.107-1.605,0.28-2.299,0.521l-0.721-4.04
				c0.693-0.268,1.533-0.486,2.52-0.66c0.986-0.173,2.146-0.26,3.48-0.26c1.92,0,3.566,0.254,4.939,0.76
				c1.375,0.506,2.5,1.2,3.381,2.08c0.879,0.88,1.527,1.92,1.939,3.12C161.649,126.989,161.856,128.282,161.856,129.668z"></path>
			<path class="clc-pattern-unit-letter" d="M124.935,121.069c0.08-0.055,0.262-0.146,0.541-0.28s0.646-0.274,1.1-0.42c0.453-0.146,1.008-0.273,1.66-0.38
				c0.654-0.106,1.395-0.16,2.221-0.16c2.266,0,3.92,0.673,4.959,2.02c1.041,1.347,1.561,3.313,1.561,5.9v15.96h5.199v4.08h-10.119
				v-20.399c0-1.281-0.254-2.147-0.76-2.601c-0.506-0.454-1.146-0.681-1.92-0.681c-0.986,0-1.814,0.134-2.48,0.4
				s-1.105,0.44-1.32,0.52L124.935,121.069z"></path>
			<path class="clc-pattern-unit-letter" d="M121.856,129.668c0,1.359-0.215,2.641-0.641,3.84c-0.426,1.2-1.08,2.246-1.961,3.141c-0.879,0.893-1.992,1.6-3.34,2.119
				c-1.346,0.521-2.953,0.78-4.82,0.78c-1.119,0-2.133-0.079-3.039-0.239s-1.826-0.428-2.76-0.801l1.08-3.96
				c0.533,0.187,1.127,0.354,1.779,0.5c0.654,0.146,1.486,0.22,2.5,0.22c1.174,0,2.154-0.14,2.939-0.42
				c0.787-0.279,1.42-0.666,1.9-1.16c0.48-0.493,0.828-1.086,1.041-1.779s0.32-1.439,0.32-2.24c0-1.734-0.486-3.094-1.461-4.08
				c-0.973-0.986-2.633-1.48-4.98-1.48c-0.773,0-1.58,0.054-2.42,0.16c-0.84,0.107-1.605,0.28-2.299,0.521l-0.721-4.04
				c0.693-0.268,1.533-0.486,2.52-0.66c0.986-0.173,2.146-0.26,3.48-0.26c1.92,0,3.566,0.254,4.939,0.76
				c1.375,0.506,2.5,1.2,3.381,2.08c0.879,0.88,1.527,1.92,1.939,3.12C121.649,126.989,121.856,128.282,121.856,129.668z"></path>
			<path class="clc-pattern-unit-letter" d="M19.362,86.158c-0.215-0.079-0.654-0.253-1.32-0.52c-0.667-0.267-1.494-0.4-2.48-0.4c-0.773,0-1.414,0.227-1.92,0.681
				c-0.507,0.453-0.76,1.319-0.76,2.601v20.399H2.762v-4.08h5.2v-15.96c0-2.587,0.52-4.554,1.561-5.9
				c1.039-1.347,2.692-2.02,4.959-2.02c0.826,0,1.566,0.054,2.221,0.16c0.652,0.106,1.206,0.233,1.66,0.38
				c0.453,0.146,0.819,0.286,1.1,0.42c0.279,0.134,0.46,0.226,0.54,0.28L19.362,86.158z"></path>
			<path class="clc-pattern-unit-letter" d="M23.702,86.918c0.412-1.2,1.06-2.24,1.939-3.12c0.881-0.88,2.006-1.574,3.381-2.08c1.373-0.506,3.02-0.76,4.939-0.76
				c1.333,0,2.493,0.087,3.48,0.26c0.986,0.174,1.826,0.393,2.52,0.66l-0.721,4.04c-0.693-0.24-1.459-0.413-2.299-0.521
				c-0.841-0.106-1.647-0.16-2.42-0.16c-2.348,0-4.008,0.494-4.98,1.48c-0.975,0.986-1.461,2.346-1.461,4.08
				c0,0.801,0.107,1.547,0.32,2.24s0.561,1.286,1.041,1.779c0.479,0.494,1.112,0.881,1.899,1.16c0.786,0.28,1.767,0.42,2.94,0.42
				c1.013,0,1.846-0.073,2.5-0.22c0.652-0.146,1.246-0.313,1.779-0.5l1.08,3.96c-0.934,0.373-1.854,0.641-2.76,0.801
				s-1.92,0.239-3.04,0.239c-1.866,0-3.474-0.26-4.819-0.78c-1.348-0.52-2.461-1.227-3.341-2.119
				c-0.88-0.895-1.534-1.94-1.96-3.141c-0.427-1.199-0.641-2.48-0.641-3.84C23.081,89.412,23.288,88.119,23.702,86.918z"></path>
			<path class="clc-pattern-unit-letter" d="M59.362,86.158c-0.215-0.079-0.654-0.253-1.32-0.52c-0.667-0.267-1.494-0.4-2.48-0.4c-0.773,0-1.414,0.227-1.92,0.681
				c-0.507,0.453-0.76,1.319-0.76,2.601v20.399h-10.12v-4.08h5.2v-15.96c0-2.587,0.52-4.554,1.561-5.9
				c1.039-1.347,2.692-2.02,4.959-2.02c0.826,0,1.566,0.054,2.221,0.16c0.652,0.106,1.206,0.233,1.66,0.38
				c0.453,0.146,0.819,0.286,1.1,0.42c0.279,0.134,0.46,0.226,0.54,0.28L59.362,86.158z"></path>
			<path class="clc-pattern-unit-letter" d="M63.702,86.918c0.412-1.2,1.06-2.24,1.939-3.12c0.881-0.88,2.006-1.574,3.381-2.08c1.373-0.506,3.02-0.76,4.939-0.76
				c1.333,0,2.493,0.087,3.48,0.26c0.986,0.174,1.826,0.393,2.52,0.66l-0.721,4.04c-0.693-0.24-1.459-0.413-2.299-0.521
				c-0.841-0.106-1.647-0.16-2.42-0.16c-2.348,0-4.008,0.494-4.98,1.48c-0.975,0.986-1.461,2.346-1.461,4.08
				c0,0.801,0.107,1.547,0.32,2.24s0.561,1.286,1.041,1.779c0.479,0.494,1.112,0.881,1.899,1.16c0.786,0.28,1.767,0.42,2.94,0.42
				c1.013,0,1.846-0.073,2.5-0.22c0.652-0.146,1.246-0.313,1.779-0.5l1.08,3.96c-0.934,0.373-1.854,0.641-2.76,0.801
				s-1.92,0.239-3.04,0.239c-1.866,0-3.474-0.26-4.819-0.78c-1.348-0.52-2.461-1.227-3.341-2.119
				c-0.88-0.895-1.534-1.94-1.96-3.141c-0.427-1.199-0.641-2.48-0.641-3.84C63.081,89.412,63.288,88.119,63.702,86.918z"></path>
			<path class="clc-pattern-unit-letter" d="M99.362,86.158c-0.215-0.079-0.654-0.253-1.32-0.52s-1.494-0.4-2.48-0.4c-0.773,0-1.414,0.227-1.92,0.681
				c-0.506,0.453-0.76,1.319-0.76,2.601v20.399h-10.12v-4.08h5.2v-15.96c0-2.587,0.52-4.554,1.561-5.9
				c1.039-1.347,2.693-2.02,4.959-2.02c0.826,0,1.566,0.054,2.221,0.16c0.652,0.106,1.207,0.233,1.66,0.38
				c0.453,0.146,0.82,0.286,1.1,0.42s0.461,0.226,0.541,0.28L99.362,86.158z"></path>
			<path class="clc-pattern-unit-letter" d="M184.935,82.199c0.08-0.055,0.262-0.146,0.541-0.28s0.646-0.274,1.1-0.42c0.453-0.146,1.008-0.273,1.66-0.38
				c0.654-0.106,1.395-0.16,2.221-0.16c2.266,0,3.92,0.673,4.959,2.02c1.041,1.347,1.561,3.313,1.561,5.9v15.96h5.199v4.08h-10.119
				V88.519c0-1.281-0.254-2.147-0.76-2.601c-0.506-0.454-1.146-0.681-1.92-0.681c-0.986,0-1.814,0.134-2.48,0.4
				s-1.105,0.44-1.32,0.52L184.935,82.199z"></path>
			<path class="clc-pattern-unit-letter" d="M181.856,90.798c0,1.359-0.215,2.641-0.641,3.84c-0.426,1.2-1.08,2.246-1.961,3.141c-0.879,0.893-1.992,1.6-3.34,2.119
				c-1.346,0.521-2.953,0.78-4.82,0.78c-1.119,0-2.133-0.079-3.039-0.239s-1.826-0.428-2.76-0.801l1.08-3.96
				c0.533,0.187,1.127,0.354,1.779,0.5c0.654,0.146,1.486,0.22,2.5,0.22c1.174,0,2.154-0.14,2.939-0.42
				c0.787-0.279,1.42-0.666,1.9-1.16c0.48-0.493,0.828-1.086,1.041-1.779s0.32-1.439,0.32-2.24c0-1.734-0.486-3.094-1.461-4.08
				c-0.973-0.986-2.633-1.48-4.98-1.48c-0.773,0-1.58,0.054-2.42,0.16c-0.84,0.107-1.605,0.28-2.299,0.521l-0.721-4.04
				c0.693-0.268,1.533-0.486,2.52-0.66c0.986-0.173,2.146-0.26,3.48-0.26c1.92,0,3.566,0.254,4.939,0.76
				c1.375,0.506,2.5,1.2,3.381,2.08c0.879,0.88,1.527,1.92,1.939,3.12C181.649,88.119,181.856,89.412,181.856,90.798z"></path>
			<path class="clc-pattern-unit-letter" d="M144.935,82.199c0.08-0.055,0.262-0.146,0.541-0.28s0.646-0.274,1.1-0.42c0.453-0.146,1.008-0.273,1.66-0.38
				c0.654-0.106,1.395-0.16,2.221-0.16c2.266,0,3.92,0.673,4.959,2.02c1.041,1.347,1.561,3.313,1.561,5.9v15.96h5.199v4.08h-10.119
				V88.519c0-1.281-0.254-2.147-0.76-2.601c-0.506-0.454-1.146-0.681-1.92-0.681c-0.986,0-1.814,0.134-2.48,0.4
				s-1.105,0.44-1.32,0.52L144.935,82.199z"></path>
			<path class="clc-pattern-unit-letter" d="M141.856,90.798c0,1.359-0.215,2.641-0.641,3.84c-0.426,1.2-1.08,2.246-1.961,3.141c-0.879,0.893-1.992,1.6-3.34,2.119
				c-1.346,0.521-2.953,0.78-4.82,0.78c-1.119,0-2.133-0.079-3.039-0.239s-1.826-0.428-2.76-0.801l1.08-3.96
				c0.533,0.187,1.127,0.354,1.779,0.5c0.654,0.146,1.486,0.22,2.5,0.22c1.174,0,2.154-0.14,2.939-0.42
				c0.787-0.279,1.42-0.666,1.9-1.16c0.48-0.493,0.828-1.086,1.041-1.779s0.32-1.439,0.32-2.24c0-1.734-0.486-3.094-1.461-4.08
				c-0.973-0.986-2.633-1.48-4.98-1.48c-0.773,0-1.58,0.054-2.42,0.16c-0.84,0.107-1.605,0.28-2.299,0.521l-0.721-4.04
				c0.693-0.268,1.533-0.486,2.52-0.66c0.986-0.173,2.146-0.26,3.48-0.26c1.92,0,3.566,0.254,4.939,0.76
				c1.375,0.506,2.5,1.2,3.381,2.08c0.879,0.88,1.527,1.92,1.939,3.12C141.649,88.119,141.856,89.412,141.856,90.798z"></path>
			<path class="clc-pattern-unit-letter" d="M104.935,82.199c0.08-0.055,0.262-0.146,0.541-0.28s0.646-0.274,1.1-0.42c0.453-0.146,1.008-0.273,1.66-0.38
				c0.654-0.106,1.395-0.16,2.221-0.16c2.266,0,3.92,0.673,4.959,2.02c1.041,1.347,1.561,3.313,1.561,5.9v15.96h5.199v4.08h-10.119
				V88.519c0-1.281-0.254-2.147-0.76-2.601c-0.506-0.454-1.146-0.681-1.92-0.681c-0.986,0-1.814,0.134-2.48,0.4
				s-1.105,0.44-1.32,0.52L104.935,82.199z"></path>
			<path class="clc-pattern-unit-letter" d="M19.362,86.158c-0.215-0.079-0.654-0.253-1.32-0.52c-0.667-0.267-1.494-0.4-2.48-0.4c-0.773,0-1.414,0.227-1.92,0.681
				c-0.507,0.453-0.76,1.319-0.76,2.601v20.399H2.762v-4.08h5.2v-15.96c0-2.587,0.52-4.554,1.561-5.9
				c1.039-1.347,2.692-2.02,4.959-2.02c0.826,0,1.566,0.054,2.221,0.16c0.652,0.106,1.206,0.233,1.66,0.38
				c0.453,0.146,0.819,0.286,1.1,0.42c0.279,0.134,0.46,0.226,0.54,0.28L19.362,86.158z"></path>
			<path class="clc-pattern-unit-letter" d="M23.702,86.918c0.412-1.2,1.06-2.24,1.939-3.12c0.881-0.88,2.006-1.574,3.381-2.08c1.373-0.506,3.02-0.76,4.939-0.76
				c1.333,0,2.493,0.087,3.48,0.26c0.986,0.174,1.826,0.393,2.52,0.66l-0.721,4.04c-0.693-0.24-1.459-0.413-2.299-0.521
				c-0.841-0.106-1.647-0.16-2.42-0.16c-2.348,0-4.008,0.494-4.98,1.48c-0.975,0.986-1.461,2.346-1.461,4.08
				c0,0.801,0.107,1.547,0.32,2.24s0.561,1.286,1.041,1.779c0.479,0.494,1.112,0.881,1.899,1.16c0.786,0.28,1.767,0.42,2.94,0.42
				c1.013,0,1.846-0.073,2.5-0.22c0.652-0.146,1.246-0.313,1.779-0.5l1.08,3.96c-0.934,0.373-1.854,0.641-2.76,0.801
				s-1.92,0.239-3.04,0.239c-1.866,0-3.474-0.26-4.819-0.78c-1.348-0.52-2.461-1.227-3.341-2.119
				c-0.88-0.895-1.534-1.94-1.96-3.141c-0.427-1.199-0.641-2.48-0.641-3.84C23.081,89.412,23.288,88.119,23.702,86.918z"></path>
			<path class="clc-pattern-unit-letter" d="M59.362,86.158c-0.215-0.079-0.654-0.253-1.32-0.52c-0.667-0.267-1.494-0.4-2.48-0.4c-0.773,0-1.414,0.227-1.92,0.681
				c-0.507,0.453-0.76,1.319-0.76,2.601v20.399h-10.12v-4.08h5.2v-15.96c0-2.587,0.52-4.554,1.561-5.9
				c1.039-1.347,2.692-2.02,4.959-2.02c0.826,0,1.566,0.054,2.221,0.16c0.652,0.106,1.206,0.233,1.66,0.38
				c0.453,0.146,0.819,0.286,1.1,0.42c0.279,0.134,0.46,0.226,0.54,0.28L59.362,86.158z"></path>
			<path class="clc-pattern-unit-letter" d="M63.702,86.918c0.412-1.2,1.06-2.24,1.939-3.12c0.881-0.88,2.006-1.574,3.381-2.08c1.373-0.506,3.02-0.76,4.939-0.76
				c1.333,0,2.493,0.087,3.48,0.26c0.986,0.174,1.826,0.393,2.52,0.66l-0.721,4.04c-0.693-0.24-1.459-0.413-2.299-0.521
				c-0.841-0.106-1.647-0.16-2.42-0.16c-2.348,0-4.008,0.494-4.98,1.48c-0.975,0.986-1.461,2.346-1.461,4.08
				c0,0.801,0.107,1.547,0.32,2.24s0.561,1.286,1.041,1.779c0.479,0.494,1.112,0.881,1.899,1.16c0.786,0.28,1.767,0.42,2.94,0.42
				c1.013,0,1.846-0.073,2.5-0.22c0.652-0.146,1.246-0.313,1.779-0.5l1.08,3.96c-0.934,0.373-1.854,0.641-2.76,0.801
				s-1.92,0.239-3.04,0.239c-1.866,0-3.474-0.26-4.819-0.78c-1.348-0.52-2.461-1.227-3.341-2.119
				c-0.88-0.895-1.534-1.94-1.96-3.141c-0.427-1.199-0.641-2.48-0.641-3.84C63.081,89.412,63.288,88.119,63.702,86.918z"></path>
			<path class="clc-pattern-unit-letter" d="M99.362,86.158c-0.215-0.079-0.654-0.253-1.32-0.52s-1.494-0.4-2.48-0.4c-0.773,0-1.414,0.227-1.92,0.681
				c-0.506,0.453-0.76,1.319-0.76,2.601v20.399h-10.12v-4.08h5.2v-15.96c0-2.587,0.52-4.554,1.561-5.9
				c1.039-1.347,2.693-2.02,4.959-2.02c0.826,0,1.566,0.054,2.221,0.16c0.652,0.106,1.207,0.233,1.66,0.38
				c0.453,0.146,0.82,0.286,1.1,0.42s0.461,0.226,0.541,0.28L99.362,86.158z"></path>
			<path class="clc-pattern-unit-letter" d="M184.935,82.199c0.08-0.055,0.262-0.146,0.541-0.28s0.646-0.274,1.1-0.42c0.453-0.146,1.008-0.273,1.66-0.38
				c0.654-0.106,1.395-0.16,2.221-0.16c2.266,0,3.92,0.673,4.959,2.02c1.041,1.347,1.561,3.313,1.561,5.9v15.96h5.199v4.08h-10.119
				V88.519c0-1.281-0.254-2.147-0.76-2.601c-0.506-0.454-1.146-0.681-1.92-0.681c-0.986,0-1.814,0.134-2.48,0.4
				s-1.105,0.44-1.32,0.52L184.935,82.199z"></path>
			<path class="clc-pattern-unit-letter" d="M181.856,90.798c0,1.359-0.215,2.641-0.641,3.84c-0.426,1.2-1.08,2.246-1.961,3.141c-0.879,0.893-1.992,1.6-3.34,2.119
				c-1.346,0.521-2.953,0.78-4.82,0.78c-1.119,0-2.133-0.079-3.039-0.239s-1.826-0.428-2.76-0.801l1.08-3.96
				c0.533,0.187,1.127,0.354,1.779,0.5c0.654,0.146,1.486,0.22,2.5,0.22c1.174,0,2.154-0.14,2.939-0.42
				c0.787-0.279,1.42-0.666,1.9-1.16c0.48-0.493,0.828-1.086,1.041-1.779s0.32-1.439,0.32-2.24c0-1.734-0.486-3.094-1.461-4.08
				c-0.973-0.986-2.633-1.48-4.98-1.48c-0.773,0-1.58,0.054-2.42,0.16c-0.84,0.107-1.605,0.28-2.299,0.521l-0.721-4.04
				c0.693-0.268,1.533-0.486,2.52-0.66c0.986-0.173,2.146-0.26,3.48-0.26c1.92,0,3.566,0.254,4.939,0.76
				c1.375,0.506,2.5,1.2,3.381,2.08c0.879,0.88,1.527,1.92,1.939,3.12C181.649,88.119,181.856,89.412,181.856,90.798z"></path>
			<path class="clc-pattern-unit-letter" d="M144.935,82.199c0.08-0.055,0.262-0.146,0.541-0.28s0.646-0.274,1.1-0.42c0.453-0.146,1.008-0.273,1.66-0.38
				c0.654-0.106,1.395-0.16,2.221-0.16c2.266,0,3.92,0.673,4.959,2.02c1.041,1.347,1.561,3.313,1.561,5.9v15.96h5.199v4.08h-10.119
				V88.519c0-1.281-0.254-2.147-0.76-2.601c-0.506-0.454-1.146-0.681-1.92-0.681c-0.986,0-1.814,0.134-2.48,0.4
				s-1.105,0.44-1.32,0.52L144.935,82.199z"></path>
			<path class="clc-pattern-unit-letter" d="M141.856,90.798c0,1.359-0.215,2.641-0.641,3.84c-0.426,1.2-1.08,2.246-1.961,3.141c-0.879,0.893-1.992,1.6-3.34,2.119
				c-1.346,0.521-2.953,0.78-4.82,0.78c-1.119,0-2.133-0.079-3.039-0.239s-1.826-0.428-2.76-0.801l1.08-3.96
				c0.533,0.187,1.127,0.354,1.779,0.5c0.654,0.146,1.486,0.22,2.5,0.22c1.174,0,2.154-0.14,2.939-0.42
				c0.787-0.279,1.42-0.666,1.9-1.16c0.48-0.493,0.828-1.086,1.041-1.779s0.32-1.439,0.32-2.24c0-1.734-0.486-3.094-1.461-4.08
				c-0.973-0.986-2.633-1.48-4.98-1.48c-0.773,0-1.58,0.054-2.42,0.16c-0.84,0.107-1.605,0.28-2.299,0.521l-0.721-4.04
				c0.693-0.268,1.533-0.486,2.52-0.66c0.986-0.173,2.146-0.26,3.48-0.26c1.92,0,3.566,0.254,4.939,0.76
				c1.375,0.506,2.5,1.2,3.381,2.08c0.879,0.88,1.527,1.92,1.939,3.12C141.649,88.119,141.856,89.412,141.856,90.798z"></path>
			<path class="clc-pattern-unit-letter" d="M104.935,82.199c0.08-0.055,0.262-0.146,0.541-0.28s0.646-0.274,1.1-0.42c0.453-0.146,1.008-0.273,1.66-0.38
				c0.654-0.106,1.395-0.16,2.221-0.16c2.266,0,3.92,0.673,4.959,2.02c1.041,1.347,1.561,3.313,1.561,5.9v15.96h5.199v4.08h-10.119
					V88.519c0-1.281-0.254-2.147-0.76-2.601c-0.506-0.454-1.146-0.681-1.92-0.681c-0.986,0-1.814,0.134-2.48,0.4
					s-1.105,0.44-1.32,0.52L104.935,82.199z"></path>
		</pattern>
	</defs>

	<rect x="0" y="0" width="2000" height="2000" fill="url(#clc-pattern-unit)"></rect>
	<!-- transform="scale(0.488064)" -->

</svg>

			</div>
		</div>
	</div>


<div class="container pt-5">
  <div class="row">
    <div class="col-lg-3">
                <nav id="TOC" role="doc-toc" class="sticky-top small pt-5">
          <h4>Contents</h4>
        <ul>
        <li><a href="#introduction"><span class="toc-section-number">1</span> Introduction</a><ul>
        <li><a href="#the-data"><span class="toc-section-number">1.1</span> The data</a></li>
        <li><a href="#the-model"><span class="toc-section-number">1.2</span> The model</a></li>
        </ul></li>
        <li><a href="#model-fitting"><span class="toc-section-number">2</span> Model fitting</a><ul>
        <li><a href="#an-example-model-a-polynomial"><span class="toc-section-number">2.1</span> An example model: a polynomial</a></li>
        <li><a href="#grid-search"><span class="toc-section-number">2.2</span> Grid search</a></li>
        <li><a href="#hill-climbing"><span class="toc-section-number">2.3</span> Hill climbing</a></li>
        </ul></li>
        <li><a href="#training-the-rnr-model"><span class="toc-section-number">3</span> Training the RnR model</a></li>
        <li><a href="#evaluating-the-rnr-model"><span class="toc-section-number">4</span> Evaluating the RnR model</a></li>
        <li><a href="#bibliography">References</a></li>
        </ul>
        </nav>
            </div>
    <div class="col-lg-9 content">
<p><strong>Goals.</strong> The goal of this computer lab is that you train a segmentation model, fitting its parameters to empirical data, and evaluate its performance. The model that you will train is the Retention&amp;Recognition model (RnR henceforth). You can find a short description of the model in <span class="citation" data-cites="alhama2015should">Alhama, Scha, and Zuidema (<a href="#ref-alhama2015should">2015</a>)</span> and in the slides in the <code>materials/</code> directory. We will use the data and evaluation procedures described in <span class="citation" data-cites="frank2010modeling">Frank et al. (<a href="#ref-frank2010modeling">2010</a>)</span>.</p>
<p><strong>Requirements.</strong> You need to write and run codes in python and the core libraries that you will use are: <code>matplotlib</code>, <code>random</code>, <code>numpy</code>, <code>scipy</code>. If you don’t have these libraries installed you can install them using <code>pip</code> or <code>conda</code>. In case you are not very familiar with drawing plots in python, you might find <a href="http://matplotlib.org/gallery.html">this <code>matplotlib</code> gallery</a> helpful.</p>
<p><strong>Materials</strong> In the <code>materials/src</code> directory, you can see 7 <code>*.py</code> files. <code>RnR.py</code> is the computational model that you will train, <code>Frank2010Results.py</code> contains methods to load the empirical data and <code>Frank2010.py</code> contains objects and methods for defining experiments. You don’t need to understand what happens in these files but you can use the functions and classes defined in these files to do this assignment. You will need to use functions defined in <code>optimization.py</code> for fitting the RnR model with the and algorithms. The main file from which you will be running your code is <code>train.ipynb</code>. This is where you should load the data, instantiate the RnR model and call your optimization functions tFinally, the file <code>polynomial.py</code> contains an example model that will be described later. o train the model.</p>
<p>In the <code>materials/data</code> directory, you can find three files, each one containing human responses for each of the three experiments described in <span class="citation" data-cites="frank2010modeling">Frank et al. (<a href="#ref-frank2010modeling">2010</a>)</span>. The name of the file indicates which experiment it corresponds to.</p>
<p><strong>Handing in.</strong> You should deliver a pdf report including the <strong>plots</strong> and <strong>explanations</strong>, and <strong>codes</strong> that you wrote (This could be the pdf version of your notebook) along with the ipython notebook you have worked on and all <strong>source files that you have edited</strong>.</p>
<h1 id="introduction"><span class="header-section-number">1</span> Introduction</h1>
<h2 id="the-data"><span class="header-section-number">1.1</span> The data</h2>
<p>As mentioned before, the goal of this assignment is for you to train and evaluate a computational model for segmentation in Artificial Language Learning. You are provided with the model (the RnR model mentioned above, and seen in the slides), and your task is to fit the parameters of this model (train the model) on the dataset that is provided.</p>
<p><span class="citation" data-cites="frank2010modeling">Frank et al. (<a href="#ref-frank2010modeling">2010</a>)</span> present three experiments to study how different factors affect word segmentation. These factors are:</p>
<ul>
<li><p><strong>Sentence length</strong><br />
This is experiment number 1. In this experiment the number of tokens and the size of the vocabulary are fixed. The sentence length is set to be 1, 2, 3, 4, 6, 8, 12 or 24.</p></li>
<li><p><strong>Number of tokens</strong><br />
This is experiment number 2. In this experiment the size of the vocabulary and sentence length are fixed. The total number of tokens in the input stream is set to be 48, 100, 300, 600, 900 or 1200.</p></li>
<li><p><strong>Size of the vocabulary</strong><br />
This is experiment number 3. In this experiment the number of tokens and the length of the sentence are fixed. The vocabulary size is set to be 3, 4, 5, 6 or 9.</p></li>
</ul>
<p>In each experiment the input stream is generated pseudo-randomly to satisfy the specified criteria. After being exposed to this stream, the participants answer a 2AFC test in which they choose between words and partwords. These responses are collected in three data files. You can find these files in <code>materials/data</code> directory (<code>E1_data.csv</code>, <code>E2_data.csv</code>, <code>E3_data.csv</code>).</p>
<div class="exercise">
<p>To see what the input stream for experiment 1 looks like, you can run the following code:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1-1" data-line-number="1"><span class="im">import</span> Frank2010</a>
<a class="sourceLine" id="cb1-2" data-line-number="2">expId <span class="op">=</span> <span class="dv">1</span> <span class="co"># Change to 2 or 3 to see the input stream for experiment 2 or 3</span></a>
<a class="sourceLine" id="cb1-3" data-line-number="3">exp <span class="op">=</span> Frank2010.experiment(expId, data_dir<span class="op">=</span><span class="st">&#39;../data/&#39;</span>)</a>
<a class="sourceLine" id="cb1-4" data-line-number="4"><span class="cf">for</span> cnd, expcnd <span class="kw">in</span> exp.cnd.items():</a>
<a class="sourceLine" id="cb1-5" data-line-number="5">    <span class="bu">print</span>(Frank2010.CONDITION[expId] <span class="op">+</span> <span class="st">&quot;: &quot;</span> <span class="op">+</span> <span class="bu">str</span>(cnd))</a>
<a class="sourceLine" id="cb1-6" data-line-number="6">    <span class="bu">print</span>(expcnd.stream)</a></code></pre></div>
<p><em>If you run into problems when trying to import <code>Frank2010</code> from outside the <code>materials/src</code> directory, first add the directory to your path:</em></p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb2-1" data-line-number="1"><span class="im">import</span> sys</a>
<a class="sourceLine" id="cb2-2" data-line-number="2">sys.path.append(<span class="st">&#39;../relative/path/to/materials/src&#39;</span>)</a>
<a class="sourceLine" id="cb2-3" data-line-number="3"><span class="im">import</span> Frank2010</a></code></pre></div>
</div>
<p>If you instantiate the experiment using <code>exp = Frank2010.experiment(expId)</code>, the data of human responses is already loaded and you can access it as follows:</p>
<ul>
<li><p><code>exp.expResults</code> is the loaded and processed human response data</p></li>
<li><p><code>exp.expResults.data</code> is a list of tuples containing the condition, subject, and if he/she was correct or not</p></li>
<li><p><code>exp.expResults.performance</code> is performance of each subject for each condition</p></li>
<li><p><code>exp.expResults.avg_performance</code> is average performance of all subjects for each condition</p></li>
<li><p><code>exp.expResults.std_performance</code> is standard deviation of performance of all subjects on each condition</p></li>
<li><p><code>exp.plotPerformance()</code> plots the responses of the humans in the experiment</p></li>
</ul>
<h2 id="the-model"><span class="header-section-number">1.2</span> The model</h2>
<p>As mentioned above the RnR model is a probabilistic segmentation model. Given a stream of syllables, it breaks it into segments. The model works based on two probabilities, the recognition probability and the retention probability. You can read more about this model in <span class="citation" data-cites="alhama2015should">Alhama, Scha, and Zuidema (<a href="#ref-alhama2015should">2015</a>)</span>. The recognition and retention probabilities of a segment <span class="math inline">\(s\)</span> are computed as follows:</p>
<p><span class="math display">\[
P_{\text{rec}}(s)  =  (1 - B^{\text{activation}(s)}) \cdot D^{\#\text{types}}
\]</span></p>
<p><span class="math display">\[
P_{\text{ret}}(s)  = A^{\text{length}(s)} \cdot  C^{\pi}
\]</span></p>
<p>As you can see. The model involves 4 parameters <span class="math inline">\(A,B,C\)</span> and <span class="math inline">\(D\)</span> that should be fitted to the empirical data.</p>
<div class="exercise">
<p>This is an example of how you can instantiate the RnR model in your code, for a given parameter setting:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb3-1" data-line-number="1"><span class="im">import</span> RnR</a>
<a class="sourceLine" id="cb3-2" data-line-number="2">rnr_model <span class="op">=</span> RnR.RnRv2(A<span class="op">=</span><span class="fl">0.04</span>, B<span class="op">=</span><span class="fl">0.3</span>, C<span class="op">=</span><span class="fl">0.3</span>, D<span class="op">=</span><span class="fl">0.3</span>, nmax<span class="op">=</span><span class="dv">4</span>)</a></code></pre></div>
<p>You can run the RnR model and see the words it memorizes by running this code:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb4-1" data-line-number="1"><span class="cf">for</span> cnd, expcnd <span class="kw">in</span> exp.cnd.items():</a>
<a class="sourceLine" id="cb4-2" data-line-number="2">    memory <span class="op">=</span> rnr_model.memorizeOnline(<span class="st">&quot;##&quot;</span>.join(expcnd.stimuli))</a>
<a class="sourceLine" id="cb4-3" data-line-number="3">    <span class="bu">print</span>(memory)</a></code></pre></div>
</div>
<p>In order to test the performance of the model, after each input stream, a list of pairs of sequences consisting of one word and one partword will be given to the model, and it has to decide which of the sequences is more likely to be a word.</p>
<p>These test pairs are stored in <code>expcnd.test</code>. The output of the RnR model consists of a memory of segments, together with their subjective frequencies. In order to convert that output to the probabilities of choosing a test item, we use the Luce rule, which states that, given two alternative options <span class="math inline">\(s_1\)</span> and <span class="math inline">\(s_2\)</span> to choose from (sequences in our case), the probability to choose one over the other is:</p>
<p><span class="math display">\[P(s_1) = \frac{\text{score}(s_1)}{\text{score}(s_1)+\text{score}(s_2)}\]</span></p>
<p>where score is, in the case of the RnR model, a subjective frequency. In the code, we call the Luce choice rule as follows:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb5-1" data-line-number="1">prob_x, prob_y, chosen <span class="op">=</span> rnr_model.Luce(pair[<span class="dv">0</span>], pair[<span class="dv">1</span>])</a></code></pre></div>
<p>In the <code>__main__</code> method of <code>train.py</code>, you can find an example of use of the classes <code>RnR</code> and <code>Frank2010</code>. Run the code and make sure you understand it before proceeding (you don’t need to understand all code in the modules, just how they can be used).</p>
<h1 id="model-fitting"><span class="header-section-number">2</span> Model fitting</h1>
<p>Computational models normally include a set of free parameters. The behaviour of the model changes depending on the values of such parameters. Hence, after choosing a computational model, the next step is to set the parameters of the model so that the behaviour/output of the model is consistent/similar to the phenomenon that is being modelled. This is what we call <em>training</em> or <em>fitting</em> the model.</p>
<h2 id="an-example-model-a-polynomial"><span class="header-section-number">2.1</span> An example model: a polynomial</h2>
<p>Here is a simple example: we model the relation between two variables <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>. We have a set of <span class="math inline">\(n\)</span> observations <span class="math inline">\((x_i, y_i)\)</span> and now want to formulate a model that predicts the value of <span class="math inline">\(y\)</span> for a given <span class="math inline">\(x\)</span>. In other words, we want to fit a curve through the observed points <span class="math inline">\((x_i, y_i)\)</span>. After long deliberation we decide that the curve should be a polynomial of degree 2. The predicted value <span class="math inline">\(y_\text{pred}\)</span> for a given <span class="math inline">\(x\)</span> then takes the form</p>
<p><span class="math display">\[y_{\text{pred}}(x) = Ax^{2} + Bx + C,\]</span></p>
<p>where <span class="math inline">\(A\)</span>, <span class="math inline">\(B\)</span> and <span class="math inline">\(C\)</span> are the parameters of the model. (Since the prediction depends on the parameters, it would be better to write <span class="math inline">\(y_{\text{pred}}(x \mid A, B, C)\)</span>)</p>
<p>Now we have to choose the values of these parameters in order to get a curve that best approximates the data points. But what do we mean by best approximation? We formally define this using an <em>objective function</em>. This function measures either how <em>well</em> your predictions fit the observed data, or how <em>poorly</em> (then it’s often called a <em>cost function</em>). During the training phase you want to maximize or minimize the objective funciton. In other words, we want to find the parameters values that result in the best between predictions and observations, as measured by the objective function.</p>
<p>In this example, we can define the objective function as the (mean absolute) difference between observed values <span class="math inline">\(y_i\)</span> and the values <span class="math inline">\(y_{\text{pred}}(x_i)\)</span> predicted by our polynomial model. This would be a cost function which we want to minimize. For the mathematically inclined, you could define it as follows:</p>
<p><span class="math display">\[
C(\text{observations}, \text{params}) = \frac{1}{n} \sum_{i=1}^n | y_i - y_{\text{pred}}(x_i \mid A, B, C)|.
\]</span></p>
<p>One thing to consider is that, depending on the data points, it is not always possible to find the set of parameters that gives us an objective function with minimum possible value (zero in this case).</p>
<div class="question">
<p>For this polynomial model, what is the maximum number of observations <span class="math inline">\((x_i, y_i)\)</span> for which can always find a set of parameters that make the objective function be zero? (Assume all <span class="math inline">\(x_i\)</span>’s are distinct.) <em>(1 point)</em></p>
<p><strong>Hint 1:</strong> If you have a model with <span class="math inline">\(k\)</span> parameters and you have <span class="math inline">\(n\)</span> data points, this gives you m equations with n variables (parameters). If <span class="math inline">\(n == k\)</span> then you will find exactly one valid value for each variable (parameter). If <span class="math inline">\(m &lt; n\)</span> the equations would have more than 1 answer and if <span class="math inline">\(n &gt; k\)</span> there would be no solution at all.</p>
<p><strong>Hint 2:</strong> Consider a linear model, <span class="math inline">\(y_{\text{pred}}(x) = Ax + B\)</span>, where there are two parameters. If you have one point, you can have infinite number of lines that go through the point. If you have two points, there is only one lines that passes both of the points. Then if you add a third point, if it is not on the same line as the first two points, you can not have a line that passes all the three points.</p>
</div>
<h2 id="grid-search"><span class="header-section-number">2.2</span> Grid search</h2>
<p>Now, if we have the model, the objective function, and the data points, how can we find the best set of values for the parameters? The algorithms that are used to find the best set of values for the parameters of a model are called <em>optimization</em> algorithms. Here, we look at two different optimization algorithm: <em>grid search</em> and <em>hill climbing</em>.</p>
<p>One way to find the optimal parameter setting is to compute the objective function for all possible equidistant combinations of different values for the parameters, and then choose the combination that gives us the lowest cost (the output of the cost function). This method is called <a href="https://en.wikipedia.org/wiki/Hyperparameter_optimization#Grid_search">grid search</a>.</p>
<p>In the example model, set <span class="math inline">\(C\)</span> to a random value, and assume <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> can be any real value in the range <span class="math inline">\([-1,1]\)</span>. We have to pick a step size, let’s say 0.1. (Since there are indefinite possible values we pick a step size in order to pick a sample.) Thus we would have 21 possible values for both <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>: <span class="math display">\[
    \{-1,-.9,-.8,0.7,...,0,.1,.2,...,.9,1\}
\]</span> If we take all possible combinations, we would have <span class="math inline">\(21 \times 21\)</span> parameter settings. This gives us the grid in the <a href="#grid">figure below</a>.</p>
<figure>
<img src="figures/grid.png" alt="Parameter search space for grid search in the example model" /><figcaption>Parameter search space for grid search in the example model</figcaption>
</figure>
<div class="question">
<p>The example model just discussed is implemented in <code>polynomial.py</code>. You can initialize it and generate training data as follows:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb6-1" data-line-number="1"><span class="im">from</span> polynomial <span class="im">import</span> PolynomialModel</a>
<a class="sourceLine" id="cb6-2" data-line-number="2">model <span class="op">=</span> PolynomialModel(A_init<span class="op">=</span><span class="dv">2</span>, B_init<span class="op">=</span><span class="dv">3</span>, C_init<span class="op">=</span>.<span class="dv">75</span>)</a>
<a class="sourceLine" id="cb6-3" data-line-number="3">data <span class="op">=</span> PolynomialModel.generate_training_data(num_datapoints<span class="op">=</span><span class="dv">30</span>)</a></code></pre></div>
<p>Look at the code and make sure you understand how it works and what else you can do with it. The model has a method that allows you to do a grid search. Plot a heatmap showing the cost function for different values of <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>. <em>(1 point)</em></p>
</div>
<div class="question">
<p>Write a function that takes a model and data as arguments, plots the data as black dots and shows the model curve as a solid red line on top of it. Give the curve a label with the model parameters (something like <span class="math inline">\(y = .25x^2 + .61x + 1\)</span>). Use this function to plot the best model found with grid search. Are the parameters good ones and why? If not, how can you change the initial parameters to get a better fit? <em>(1 point)</em></p>
</div>
<h2 id="hill-climbing"><span class="header-section-number">2.3</span> Hill climbing</h2>
<p>There are several methods that help us avoid exploring the whole space of the parameter values, using greedy decisions to directly explore the space in the direction that is more probably closer to the minimum point. One of those is the hill climbing algorithm.</p>
<p><a href="https://en.wikipedia.org/wiki/Hill_climbing">Hill climbing</a> is a so called local search algorithm. The idea behind it is that you start from a random point (where each point is a possible solution for the problem), then you decide in which direction you should change the parameters based on the value of the cost function at the current point and its neighbours. Greedily, in each iteration, you choose the next point to be where the cost function is the lowest.</p>
<p>There exist different versions of this algorithm. Here, we will implement <em>simple hill climbing</em>. Informally, you can think about simple hill climbing as if you were lost in some huge hilly landscape and your goal is to find the highest point. If you follow this algorithm, you would make a step from where you are, in one random direction, and see if you have moved higher. If so, you choose your next random direction from this point; if, instead, the landscape goes down, then you go back where you were and choose another random direction.</p>
<div class="question">
<p>The file <code>polynomial.py</code> contains an implementation of the simple hill climbing algorithm for the polynomial model. Carefully look at the code and figure out how it works. Train the polynomial using hill climbing. Plot the cost after every parameter update, and make a plot showing the model fit after training. <em>(1 point)</em></p>
</div>
<div class="question">
<p>If you would run the hill climbing algorithm multiple times, chances are the algorithm converges to different parameter settings every time. This is due to the randomness in the initial condition and in choosing the next step.</p>
<ol type="1">
<li><p>Write a function that trains a model 100 times on a given dataset, and returns (1) the parameter values found in every run, and (2) the final cost. <em>(0.5 points)</em></p></li>
<li><p>Next, write a function that plots the distribution of values every variable takes over the 500 runs. This shows you which local minima different runs tend to end up in. You can use matplotlib to draw simple <a href="https://pythonspot.com/matplotlib-histogram/">histograms</a>, but you might also want to look at the python library <a href="https://seaborn.pydata.org">seaborn</a> which allows you to easily make <a href="https://seaborn.pydata.org/examples/simple_violinplots.html">violin plots</a>, <a href="https://seaborn.pydata.org/generated/seaborn.stripplot.html?highlight=stripplot#seaborn.stripplot">stripplots</a> and much more. <em>(0.5 points)</em></p></li>
<li>Plot the parameter distributions for (at least) two different datasets: one with 5 datapoints, and one with 500 datapoints. Can you explain what you see? <em>(1 point)</em></li>
</ol>
</div>
<h1 id="training-the-rnr-model"><span class="header-section-number">3</span> Training the RnR model</h1>
<p>Now that you know what does it mean to fit a model to some data, you are ready to train the RnR model. In the RnR model, there are 4 parameters to be tuned <span class="math inline">\((A, B, C, D)\)</span>, and they all should be in the range of <span class="math inline">\((0,1)\)</span>. The goal is to set these parameters in a way that this model behaves as similar as possible to humans in doing the segmentation task. The objective function is <a href="https://en.wikipedia.org/wiki/Pearson_correlation_coefficient">Pearson’s <span class="math inline">\(r\)</span></a>, which computes the correlation between the performances of the model and the average performances of humans for different conditions.</p>
<div class="question">
<p>Apply grid search to fit the parameters of the RnR model for each of the experiments separately. Choose step size of 0.01 (if this is too slow for your computer, choose a larger step size, such as 0.1, and report it). What is the best correlation that you get? <em>(1 point)</em></p>
<p><strong>Hint:</strong> You can use <code>exp.pearsonR(performances)</code> to compute the cost.</p>
</div>
<div class="question">
<p>Apply hill climbing to fit the parameters of the RnR model for each of the experiments separately. What is the best correlation that you get? Do you get similar results as with grid search? Why? Draw a plot to show how the cost changes after each iteration.</p>
</div>
<h1 id="evaluating-the-rnr-model"><span class="header-section-number">4</span> Evaluating the RnR model</h1>
<div class="question">
<p>For each of the three fitted models that you got from the hill climbing search algorithm, draw a plot that compares the performance of humans with the performance of the model. What can you conclude? (1 point)</p>
</div>
<div class="question">
<p>In this assignment, we have fitted the three datasets independently, so we end up with three different models. What would be a better practice? Can you think of a training setup in which we can make sure that the parameters <em>generalize</em> (i.e. do not overfit the data)? <em>You do not need to write any code, just reason about this</em></p>
</div>
<h1 id="bibliography" class="unnumbered">References</h1>
<div id="refs" class="references">
<div id="ref-alhama2015should">
<p>Alhama, Raquel G, Remko Scha, and Willem Zuidema. 2015. “How Should We Evaluate Models of Segmentation in Artificial Language Learning?” In <em>Proceedings of 13th International Conference on Cognitive Modeling</em>.</p>
</div>
<div id="ref-frank2010modeling">
<p>Frank, Michael C, Sharon Goldwater, Thomas L Griffiths, and Joshua B Tenenbaum. 2010. “Modeling Human Performance in Statistical Word Segmentation.” <em>Cognition</em> 117 (2). Elsevier: 107–25.</p>
</div>
</div>
    </div>
  </div>
</div>

</article>
<script src="http://projects.illc.uva.nl/LaCo/clclab/assets/bundle.js"></script>
</body>
</html>